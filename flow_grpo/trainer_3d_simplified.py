"""
ç®€åŒ–ç‰ˆHunyuan3D GRPO Trainer - ä»¿ç…§SD3çš„ç®€æ´æ–¹å¼

ä¸»è¦ç®€åŒ–ï¼š
1. ç§»é™¤å¤æ‚çš„è®¾å¤‡æ£€æŸ¥å’Œå†…å­˜ç›‘æ§
2. ç®€åŒ–æ¡ä»¶å¤„ç†
3. ä½¿ç”¨acceleratorç»Ÿä¸€ç®¡ç†è®¾å¤‡
4. ç®€åŒ–é”™è¯¯å¤„ç†
"""

import torch
import numpy as np
from typing import Dict, List, Optional, Tuple, Any, Union
from collections import defaultdict
from concurrent import futures

from generators.hunyuan3d.pipeline import Hunyuan3DPipeline
from reward_models.rewards_mesh import multi_mesh_score
from .diffusers_patch.hunyuan3d_pipeline_with_logprob import hunyuan3d_pipeline_with_logprob
from .diffusers_patch.hunyuan3d_sde_with_logprob import hunyuan3d_sde_step_with_logprob


class Hunyuan3DGRPOTrainer:
    """ç®€åŒ–ç‰ˆGRPO Trainer for Hunyuan3D"""
    
    def __init__(
        self,
        pipeline: Hunyuan3DPipeline,
        reward_config: Optional[Dict[str, float]] = None,
        device: str = "cuda",
    ):
        """
        åˆå§‹åŒ–ç®€åŒ–ç‰ˆè®­ç»ƒå™¨
        
        Args:
            pipeline: Hunyuan3DPipelineå®ä¾‹
            reward_config: å¥–åŠ±å‡½æ•°é…ç½®
            device: è®¾å¤‡
        """
        self.pipeline = pipeline
        self.device = device
        
        # é»˜è®¤å¥–åŠ±é…ç½®
        if reward_config is None:
            reward_config = {"geometric_quality": 0.3, "uni3d": 0.7}
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥åˆ›å»ºå¥–åŠ±å‡½æ•°
        self.reward_fn = multi_mesh_score(device, reward_config)
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥ç§»åŠ¨åˆ°è®¾å¤‡
        self.pipeline.core_pipeline.to(device)
    
    def sample_meshes_with_rewards(
        self,
        images: List[str],
        num_inference_steps: int = 50,
        guidance_scale: float = 5.0,
        deterministic: bool = False,
        kl_reward: float = 0.0,
        octree_resolution: int = 384,
        mc_level: float = 0.0,
        mc_algo: str = None,
        box_v: float = 1.01,
        num_chunks: int = 8000,
        executor: Optional[futures.ThreadPoolExecutor] = None,
    ) -> Dict[str, Any]:
        """
        ç®€åŒ–ç‰ˆé‡‡æ ·å‡½æ•°
        
        Args:
            images: è¾“å…¥å›¾åƒè·¯å¾„åˆ—è¡¨
            num_inference_steps: æ¨ç†æ­¥æ•°
            guidance_scale: å¼•å¯¼scale
            deterministic: æ˜¯å¦ç¡®å®šæ€§
            kl_reward: KLå¥–åŠ±ç³»æ•°
            å…¶ä»–å‚æ•°: meshç”Ÿæˆå‚æ•°
            
        Returns:
            åŒ…å«latents, log_probs, kl, rewardsç­‰çš„å­—å…¸
        """
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥å¤„ç†å›¾åƒ
        from PIL import Image
        pil_images = [Image.open(img_path).convert('RGBA') for img_path in images]
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥ç¼–ç æ¡ä»¶
        core_pipeline = self.pipeline.core_pipeline
        cond_inputs = core_pipeline.prepare_image(pil_images)
        image_tensor = cond_inputs.pop('image')
        
        # ğŸš€ ç¼–ç æ­£é¢å›¾åƒæ¡ä»¶ï¼ˆä¸ä½¿ç”¨CFGï¼‰
        positive_image_cond = core_pipeline.encode_cond(
            image=image_tensor,
            additional_cond_inputs=cond_inputs,
            do_classifier_free_guidance=False,  # åˆ†ç¦»ç¼–ç 
            dual_guidance=False,  # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ ç¼ºå¤±çš„dual_guidanceå‚æ•°
        )
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨pipelineç”Ÿæˆ
        meshes, all_latents, all_log_probs, all_kl = hunyuan3d_pipeline_with_logprob(
            core_pipeline,
            image=pil_images,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            deterministic=deterministic,
            kl_reward=kl_reward,
            positive_image_cond=positive_image_cond,
            octree_resolution=octree_resolution,
            mc_level=mc_level,
            mc_algo=mc_algo,
            box_v=box_v,
            num_chunks=num_chunks,
        )
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è®¡ç®—å¥–åŠ±
        rewards, reward_metadata = self.reward_fn(meshes, images, {}, images=images)
        
        # ğŸš€ ç®€åŒ–ï¼šä»rewardå­—å…¸ä¸­æå–å¹³å‡åˆ†æ•°
        if isinstance(rewards, dict):
            # multi_mesh_scoreè¿”å›ä¸€ä¸ªå­—å…¸ï¼Œä½¿ç”¨'avg'é”®çš„å€¼
            avg_rewards = rewards.get('avg', [0.0] * len(meshes))
        else:
            # å¦‚æœæ˜¯åˆ—è¡¨æˆ–æ•°å­—ï¼Œç›´æ¥ä½¿ç”¨
            avg_rewards = rewards if isinstance(rewards, list) else [rewards]
        
        # ç¡®ä¿å¥–åŠ±æ˜¯æ•°å­—åˆ—è¡¨
        if not isinstance(avg_rewards, list):
            avg_rewards = [avg_rewards]
        
        rewards_tensor = {
            "avg": torch.tensor(avg_rewards, device=self.device, dtype=torch.float32)
        }
        
        return {
            "meshes": meshes,
            "images": images,
            "prompts": [f"3D model from {img}" for img in images],
            "latents": all_latents,
            "log_probs": all_log_probs,
            "kl": all_kl,
            "rewards": rewards_tensor,
            "timesteps": torch.arange(num_inference_steps, device=self.device).unsqueeze(0).repeat(len(images), 1),
            "positive_image_cond": positive_image_cond,
            "metadata": reward_metadata,
        }
    
    def compute_log_prob_3d(
        self,
        pipeline,
        sample: Dict[str, torch.Tensor],
        step_index: int,
        config: Any,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        ç®€åŒ–ç‰ˆlogæ¦‚ç‡è®¡ç®—
        
        Args:
            pipeline: ç®¡é“
            sample: æ ·æœ¬æ•°æ®
            step_index: æ—¶é—´æ­¥ç´¢å¼•
            config: é…ç½®
            
        Returns:
            (prev_sample, log_prob, prev_sample_mean, std_dev)
        """
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è·å–æ•°æ®
        latents = sample["latents"][:, step_index]
        next_latents = sample["next_latents"][:, step_index]
        timestep = sample["timesteps"][:, step_index]
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨æ¡ä»¶
        if "positive_image_cond" in sample:
            cond = sample["positive_image_cond"]
            if isinstance(cond, dict) and 'main' in cond:
                cond = cond['main']
        else:
            raise ValueError("No image conditions found in sample")
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥é¢„æµ‹å™ªå£°
        with torch.amp.autocast('cuda'):
            contexts = {'main': cond}
            noise_pred = pipeline.model(latents, timestep.float(), contexts)
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è®¡ç®—logæ¦‚ç‡
        deterministic = getattr(config, 'deterministic', False)
        
        prev_sample, log_prob, prev_sample_mean, std_dev = hunyuan3d_sde_step_with_logprob(
            scheduler=pipeline.scheduler,
            model_output=noise_pred,
            timestep=timestep[0],
            sample=latents,
            prev_sample=next_latents,
            deterministic=deterministic,
        )
        
        return prev_sample, log_prob, prev_sample_mean, std_dev
    
    def train_step(
        self,
        samples: Dict[str, torch.Tensor],
        pipeline,
        optimizer: torch.optim.Optimizer,
        config: Any,
        accelerator: Any,
    ) -> Dict[str, float]:
        """
        ç®€åŒ–ç‰ˆè®­ç»ƒæ­¥éª¤
        
        Args:
            samples: æ ·æœ¬æ•°æ®
            pipeline: ç®¡é“
            optimizer: ä¼˜åŒ–å™¨
            config: é…ç½®
            accelerator: åŠ é€Ÿå™¨
            
        Returns:
            è®­ç»ƒæŒ‡æ ‡å­—å…¸
        """
        info = defaultdict(list)
        num_timesteps = samples["timesteps"].shape[1]
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è®­ç»ƒæ¯ä¸ªæ—¶é—´æ­¥
        for j in range(num_timesteps):
            with accelerator.accumulate(pipeline.model):
                with accelerator.autocast():
                    # è®¡ç®—logæ¦‚ç‡
                    prev_sample, log_prob, prev_sample_mean, std_dev = self.compute_log_prob_3d(
                        pipeline, samples, j, config
                    )
                    
                    # å‚è€ƒlogæ¦‚ç‡ï¼ˆå¦‚æœéœ€è¦KLæ­£åˆ™åŒ–ï¼‰
                    if getattr(config.train, 'beta', 0) > 0:
                        with torch.no_grad():
                            with pipeline.model.disable_adapter():
                                _, log_prob_ref, _, _ = self.compute_log_prob_3d(
                                    pipeline, samples, j, config
                                )
                    else:
                        log_prob_ref = log_prob
                
                # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è®¡ç®—GRPOæŸå¤±
                advantages = torch.clamp(
                    samples["advantages"],
                    -getattr(config.train, 'adv_clip_max', 5.0),
                    getattr(config.train, 'adv_clip_max', 5.0),
                )
                
                # å¦‚æœadvantagesæ˜¯2Dçš„ï¼Œå–å¯¹åº”æ—¶é—´æ­¥
                if advantages.dim() == 2:
                    advantages = advantages[:, j]
                
                # è®¡ç®—æ¯”ç‡
                ratio = torch.exp(log_prob - samples["log_probs"][:, j])
                
                # PPOæŸå¤±
                loss1 = -advantages * ratio
                loss2 = -advantages * torch.clamp(
                    ratio,
                    1.0 - getattr(config.train, 'clip_range', 0.2),
                    1.0 + getattr(config.train, 'clip_range', 0.2),
                )
                loss = torch.max(loss1, loss2).mean()
                
                # KLæŸå¤±
                if getattr(config.train, 'beta', 0) > 0:
                    kl_loss = getattr(config.train, 'beta', 0) * (log_prob - log_prob_ref)
                    loss = loss + kl_loss.mean()
                
                # ğŸš€ ç®€åŒ–ï¼šç›´æ¥åå‘ä¼ æ’­
                accelerator.backward(loss)
                
                # æ¢¯åº¦è£å‰ª
                if getattr(config.train, 'max_grad_norm', None) is not None:
                    accelerator.clip_grad_norm_(
                        pipeline.model.parameters(),
                        config.train.max_grad_norm
                    )
                
                optimizer.step()
                optimizer.zero_grad()
                
                # è®°å½•æŒ‡æ ‡
                info["loss"].append(loss.item())
                info["ratio"].append(ratio.mean().item())
                info["advantages"].append(advantages.mean().item())
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è¿”å›å¹³å‡æŒ‡æ ‡
        return {k: np.mean(v) for k, v in info.items()} 