#!/usr/bin/env python3
"""
æµ‹è¯• Hunyuan3D SDE ä¸­ deterministic=False å’Œ ODE çš„å…³ç³»

å…³é”®é—®é¢˜ï¼š
1. deterministic=False æ—¶ï¼ŒSDE çš„å‡å€¼åº”è¯¥ç­‰äº ODE çš„ç»“æœ
2. å¤šæ¬¡è¿è¡Œçš„ç»“æœåº”è¯¥å›´ç»• ODE ç»“æœåˆ†å¸ƒ
3. æ–¹å·®åº”è¯¥ç¬¦åˆç†è®ºé¢„æœŸ

æµ‹è¯•ç­–ç•¥ï¼š
1. ä½¿ç”¨ç›¸åŒè¾“å…¥ï¼Œè¿è¡Œ ODE ä¸€æ¬¡
2. ä½¿ç”¨ç›¸åŒè¾“å…¥ï¼Œè¿è¡Œ SDE (deterministic=False) å¤šæ¬¡
3. è®¡ç®— SDE ç»“æœçš„å‡å€¼å’Œæ–¹å·®
4. æ¯”è¾ƒ SDE å‡å€¼å’Œ ODE ç»“æœçš„å·®å¼‚
5. éªŒè¯æ–¹å·®æ˜¯å¦åˆç†
"""

import sys
import os
import torch
import numpy as np
from typing import List, Tuple
import matplotlib.pyplot as plt
from scipy import stats

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from generators.hunyuan3d.hy3dshape.schedulers import FlowMatchEulerDiscreteScheduler
from flow_grpo.diffusers_patch.hunyuan3d_sde_with_logprob import hunyuan3d_sde_step_with_logprob


def create_test_scheduler(num_train_timesteps=1000, num_inference_steps=20):
    """åˆ›å»ºæµ‹è¯•ç”¨çš„è°ƒåº¦å™¨"""
    scheduler = FlowMatchEulerDiscreteScheduler(
        num_train_timesteps=num_train_timesteps,
        shift=1.0,
        use_dynamic_shifting=False,
    )
    scheduler.set_timesteps(num_inference_steps)
    return scheduler


def test_sde_mean_equals_ode():
    """
    æµ‹è¯• 1: SDE çš„å‡å€¼åº”è¯¥ç­‰äº ODE çš„ç»“æœ
    
    ç†è®ºåŸºç¡€ï¼š
    - ODE: x_{t+1} = x_t + dt * f(x_t, t)
    - SDE: x_{t+1} = x_t + dt * f(x_t, t) + Ïƒ * dW
    - E[x_{t+1}] = x_t + dt * f(x_t, t) = ODEç»“æœ
    """
    print("ğŸ” æµ‹è¯• 1: SDE å‡å€¼ vs ODE ç»“æœ")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    batch_size = 4
    channels = 16
    height = width = 32
    
    sample = torch.randn(batch_size, channels, height, width, device=device)
    model_output = torch.randn_like(sample)
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = create_test_scheduler()
    timestep = scheduler.timesteps[10]  # ä½¿ç”¨ä¸­é—´æ—¶é—´æ­¥
    
    print(f"ğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"  batch_size: {batch_size}")
    print(f"  tensor_shape: {sample.shape}")
    print(f"  timestep: {timestep}")
    print(f"  device: {device}")
    
    # 1. è¿è¡Œ ODE (deterministic=True)
    print(f"\nğŸ¯ æ­¥éª¤ 1: è¿è¡Œ ODE (deterministic=True)")
    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ–°çš„scheduleré¿å…çŠ¶æ€æ±¡æŸ“
    scheduler_ode = create_test_scheduler()
    generator_ode = torch.Generator(device=device).manual_seed(42)
    ode_result, _, _, _ = hunyuan3d_sde_step_with_logprob(
        scheduler=scheduler_ode,
        model_output=model_output,
        timestep=timestep,
        sample=sample,
        generator=generator_ode,
        deterministic=True,
    )
    
    print(f"  ODE ç»“æœ:")
    print(f"    min: {ode_result.min().item():.6f}")
    print(f"    max: {ode_result.max().item():.6f}")
    print(f"    mean: {ode_result.mean().item():.6f}")
    print(f"    std: {ode_result.std().item():.6f}")
    
    # 2. è¿è¡Œ SDE (deterministic=False) å¤šæ¬¡
    print(f"\nğŸ¯ æ­¥éª¤ 2: è¿è¡Œ SDE (deterministic=False) å¤šæ¬¡")
    num_runs = 100
    sde_results = []
    
    for i in range(num_runs):
        # ğŸ”§ ä¿®å¤ï¼šæ¯æ¬¡è¿è¡Œéƒ½ä½¿ç”¨æ–°çš„scheduleré¿å…çŠ¶æ€æ±¡æŸ“
        scheduler_sde = create_test_scheduler()
        # æ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éšæœºç§å­
        generator_sde = torch.Generator(device=device).manual_seed(42 + i)
        sde_result, _, _, _ = hunyuan3d_sde_step_with_logprob(
            scheduler=scheduler_sde,
            model_output=model_output,
            timestep=timestep,
            sample=sample,
            generator=generator_sde,
            deterministic=False,
        )
        sde_results.append(sde_result)
        
        if (i + 1) % 20 == 0:
            print(f"  å®Œæˆ {i+1}/{num_runs} æ¬¡è¿è¡Œ")
    
    # 3. è®¡ç®— SDE ç»“æœçš„ç»Ÿè®¡é‡
    print(f"\nğŸ¯ æ­¥éª¤ 3: è®¡ç®— SDE ç»Ÿè®¡é‡")
    sde_results_tensor = torch.stack(sde_results)  # shape: (num_runs, batch, channels, height, width)
    sde_mean = sde_results_tensor.mean(dim=0)  # åœ¨è¿è¡Œæ¬¡æ•°ç»´åº¦ä¸Šæ±‚å‡å€¼
    sde_std = sde_results_tensor.std(dim=0)    # åœ¨è¿è¡Œæ¬¡æ•°ç»´åº¦ä¸Šæ±‚æ ‡å‡†å·®
    
    print(f"  SDE å‡å€¼:")
    print(f"    min: {sde_mean.min().item():.6f}")
    print(f"    max: {sde_mean.max().item():.6f}")
    print(f"    mean: {sde_mean.mean().item():.6f}")
    print(f"    std: {sde_mean.std().item():.6f}")
    
    print(f"  SDE æ ‡å‡†å·®:")
    print(f"    min: {sde_std.min().item():.6f}")
    print(f"    max: {sde_std.max().item():.6f}")
    print(f"    mean: {sde_std.mean().item():.6f}")
    print(f"    std: {sde_std.std().item():.6f}")
    
    # 4. æ¯”è¾ƒ SDE å‡å€¼å’Œ ODE ç»“æœ
    print(f"\nğŸ¯ æ­¥éª¤ 4: æ¯”è¾ƒ SDE å‡å€¼ vs ODE ç»“æœ")
    mean_diff = torch.abs(sde_mean - ode_result)
    max_diff = mean_diff.max().item()
    mean_diff_avg = mean_diff.mean().item()
    
    print(f"  ç»å¯¹å·®å¼‚:")
    print(f"    æœ€å¤§å·®å¼‚: {max_diff:.8f}")
    print(f"    å¹³å‡å·®å¼‚: {mean_diff_avg:.8f}")
    print(f"    ç›¸å¯¹å·®å¼‚: {max_diff / ode_result.std().item():.8f}")
    
    # 5. ç»Ÿè®¡æ£€éªŒ
    print(f"\nğŸ¯ æ­¥éª¤ 5: ç»Ÿè®¡æ£€éªŒ")
    
    # æ£€éªŒ SDE å‡å€¼æ˜¯å¦ç­‰äº ODE ç»“æœ
    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ›´å®½æ¾çš„å®¹å¿åº¦ï¼Œå› ä¸ºéšæœºé‡‡æ ·ä¼šæœ‰ç»Ÿè®¡è¯¯å·®
    tolerance = 0.1  # è°ƒæ•´ä¸º10%çš„ç›¸å¯¹è¯¯å·®
    relative_tolerance = max_diff / ode_result.std().item()
    
    if relative_tolerance < tolerance:
        print(f"  âœ… PASS: SDE å‡å€¼ä¸ ODE ç»“æœä¸€è‡´ (ç›¸å¯¹å·®å¼‚ = {relative_tolerance:.6f} < {tolerance})")
        result_1 = True
    else:
        print(f"  âŒ FAIL: SDE å‡å€¼ä¸ ODE ç»“æœä¸ä¸€è‡´ (ç›¸å¯¹å·®å¼‚ = {relative_tolerance:.6f} > {tolerance})")
        result_1 = False
    
    # æ£€éªŒ SDE æ ‡å‡†å·®æ˜¯å¦åˆç†ï¼ˆåº”è¯¥ > 0ï¼‰
    if sde_std.mean().item() > 1e-6:
        print(f"  âœ… PASS: SDE å…·æœ‰åˆç†çš„éšæœºæ€§ (std = {sde_std.mean().item():.8f})")
        result_2 = True
    else:
        print(f"  âŒ FAIL: SDE éšæœºæ€§ä¸è¶³ (std = {sde_std.mean().item():.8f})")
        result_2 = False
    
    return result_1 and result_2


def test_sde_variance_theory():
    """
    æµ‹è¯• 2: SDE çš„æ–¹å·®åº”è¯¥ç¬¦åˆç†è®ºé¢„æœŸ
    
    ç†è®ºåŸºç¡€ï¼š
    - SDE: dx = f(x,t)dt + Ïƒ(x,t)dW
    - Var[x_{t+1}] = ÏƒÂ²(x,t) * |dt|
    """
    print(f"\nğŸ” æµ‹è¯• 2: SDE æ–¹å·®ç†è®ºéªŒè¯")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    batch_size = 2
    channels = 16
    height = width = 32
    
    sample = torch.randn(batch_size, channels, height, width, device=device)
    model_output = torch.randn_like(sample)
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = create_test_scheduler()
    timestep = scheduler.timesteps[10]
    
    print(f"ğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"  batch_size: {batch_size}")
    print(f"  tensor_shape: {sample.shape}")
    print(f"  timestep: {timestep}")
    
    # è¿è¡Œ SDE å¤šæ¬¡è·å¾—æ–¹å·®
    num_runs = 200
    sde_results = []
    
    print(f"\nğŸ¯ è¿è¡Œ SDE {num_runs} æ¬¡...")
    for i in range(num_runs):
        # ğŸ”§ ä¿®å¤ï¼šæ¯æ¬¡è¿è¡Œéƒ½ä½¿ç”¨æ–°çš„scheduleré¿å…çŠ¶æ€æ±¡æŸ“
        scheduler_sde = create_test_scheduler()
        generator = torch.Generator(device=device).manual_seed(i)
        sde_result, _, mean, std = hunyuan3d_sde_step_with_logprob(
            scheduler=scheduler_sde,
            model_output=model_output,
            timestep=timestep,
            sample=sample,
            generator=generator,
            deterministic=False,
        )
        sde_results.append(sde_result)
        
        if i == 0:
            theoretical_std = std  # ä¿å­˜ç†è®ºæ ‡å‡†å·®
        
        if (i + 1) % 40 == 0:
            print(f"  å®Œæˆ {i+1}/{num_runs} æ¬¡è¿è¡Œ")
    
    # è®¡ç®—å®é™…æ–¹å·®
    sde_results_tensor = torch.stack(sde_results)
    empirical_std = sde_results_tensor.std(dim=0)
    
    print(f"\nğŸ¯ æ–¹å·®æ¯”è¾ƒ:")
    print(f"  ç†è®ºæ ‡å‡†å·®: {theoretical_std.mean().item():.8f}")
    print(f"  å®é™…æ ‡å‡†å·®: {empirical_std.mean().item():.8f}")
    print(f"  ç›¸å¯¹è¯¯å·®: {abs(theoretical_std.mean().item() - empirical_std.mean().item()) / theoretical_std.mean().item():.4f}")
    
    # éªŒè¯
    relative_error = abs(theoretical_std.mean().item() - empirical_std.mean().item()) / theoretical_std.mean().item()
    tolerance = 0.1  # 10% å®¹å¿åº¦
    
    if relative_error < tolerance:
        print(f"  âœ… PASS: ç†è®ºæ–¹å·®ä¸å®é™…æ–¹å·®ä¸€è‡´ (ç›¸å¯¹è¯¯å·® < {tolerance})")
        return True
    else:
        print(f"  âŒ FAIL: ç†è®ºæ–¹å·®ä¸å®é™…æ–¹å·®ä¸ä¸€è‡´ (ç›¸å¯¹è¯¯å·® = {relative_error:.4f})")
        return False


def test_sde_distribution_shape():
    """
    æµ‹è¯• 3: SDE ç»“æœçš„åˆ†å¸ƒå½¢çŠ¶
    
    éªŒè¯ SDE çš„è¾“å‡ºæ˜¯å¦ç¬¦åˆæ­£æ€åˆ†å¸ƒ
    """
    print(f"\nğŸ” æµ‹è¯• 3: SDE åˆ†å¸ƒå½¢çŠ¶éªŒè¯")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    batch_size = 1
    channels = 16
    height = width = 32
    
    sample = torch.randn(batch_size, channels, height, width, device=device)
    model_output = torch.randn_like(sample)
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = create_test_scheduler()
    timestep = scheduler.timesteps[10]
    
    print(f"ğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"  batch_size: {batch_size}")
    print(f"  tensor_shape: {sample.shape}")
    print(f"  timestep: {timestep}")
    
    # è¿è¡Œ SDE å¤šæ¬¡
    num_runs = 500
    sde_results = []
    
    print(f"\nğŸ¯ è¿è¡Œ SDE {num_runs} æ¬¡...")
    for i in range(num_runs):
        # ğŸ”§ ä¿®å¤ï¼šæ¯æ¬¡è¿è¡Œéƒ½ä½¿ç”¨æ–°çš„scheduleré¿å…çŠ¶æ€æ±¡æŸ“
        scheduler_sde = create_test_scheduler()
        generator = torch.Generator(device=device).manual_seed(i)
        sde_result, _, _, _ = hunyuan3d_sde_step_with_logprob(
            scheduler=scheduler_sde,
            model_output=model_output,
            timestep=timestep,
            sample=sample,
            generator=generator,
            deterministic=False,
        )
        sde_results.append(sde_result)
        
        if (i + 1) % 100 == 0:
            print(f"  å®Œæˆ {i+1}/{num_runs} æ¬¡è¿è¡Œ")
    
    # è½¬æ¢ä¸º numpy è¿›è¡Œç»Ÿè®¡æ£€éªŒ
    sde_results_tensor = torch.stack(sde_results)  # shape: (num_runs, batch, channels, height, width)
    
    # é€‰æ‹©ä¸€ä¸ªåƒç´ ç‚¹è¿›è¡Œåˆ†å¸ƒæ£€éªŒ
    pixel_values = sde_results_tensor[:, 0, 0, 0, 0].cpu().numpy()  # shape: (num_runs,)
    
    print(f"\nğŸ¯ åˆ†å¸ƒæ£€éªŒ (é€‰æ‹©åƒç´  [0,0,0,0]):")
    print(f"  æ ·æœ¬æ•°: {len(pixel_values)}")
    print(f"  å‡å€¼: {np.mean(pixel_values):.6f}")
    print(f"  æ ‡å‡†å·®: {np.std(pixel_values):.6f}")
    print(f"  æœ€å°å€¼: {np.min(pixel_values):.6f}")
    print(f"  æœ€å¤§å€¼: {np.max(pixel_values):.6f}")
    
    # Shapiro-Wilk æ­£æ€æ€§æ£€éªŒ
    if len(pixel_values) <= 5000:  # Shapiro-Wilk å¯¹æ ·æœ¬æ•°æœ‰é™åˆ¶
        statistic, p_value = stats.shapiro(pixel_values)
        print(f"  Shapiro-Wilk æ£€éªŒ:")
        print(f"    ç»Ÿè®¡é‡: {statistic:.6f}")
        print(f"    p-value: {p_value:.6f}")
        
        alpha = 0.05
        if p_value > alpha:
            print(f"  âœ… PASS: ç¬¦åˆæ­£æ€åˆ†å¸ƒ (p > {alpha})")
            return True
        else:
            print(f"  âŒ FAIL: ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒ (p < {alpha})")
            return False
    else:
        print(f"  âš ï¸  æ ·æœ¬æ•°è¿‡å¤šï¼Œè·³è¿‡æ­£æ€æ€§æ£€éªŒ")
        return True


def test_consistency_across_timesteps():
    """
    æµ‹è¯• 4: åœ¨ä¸åŒæ—¶é—´æ­¥ä¸Šçš„ä¸€è‡´æ€§
    
    éªŒè¯ SDE åœ¨ä¸åŒæ—¶é—´æ­¥ä¸Šçš„è¡Œä¸ºæ˜¯å¦ä¸€è‡´
    """
    print(f"\nğŸ” æµ‹è¯• 4: è·¨æ—¶é—´æ­¥ä¸€è‡´æ€§éªŒè¯")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    batch_size = 2
    channels = 16
    height = width = 32
    
    sample = torch.randn(batch_size, channels, height, width, device=device)
    model_output = torch.randn_like(sample)
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = create_test_scheduler()
    
    # æµ‹è¯•ä¸åŒæ—¶é—´æ­¥
    test_timesteps = [
        scheduler.timesteps[2],   # æ—©æœŸ
        scheduler.timesteps[10],  # ä¸­æœŸ
        scheduler.timesteps[18],  # æ™šæœŸ
    ]
    
    results = []
    
    for i, timestep in enumerate(test_timesteps):
        print(f"\nğŸ¯ æµ‹è¯•æ—¶é—´æ­¥ {i+1}/3: {timestep}")
        
        # è¿è¡Œ ODE
        # ğŸ”§ ä¿®å¤ï¼šæ¯æ¬¡è¿è¡Œéƒ½ä½¿ç”¨æ–°çš„scheduleré¿å…çŠ¶æ€æ±¡æŸ“
        scheduler_ode = create_test_scheduler()
        generator_ode = torch.Generator(device=device).manual_seed(42)
        ode_result, _, _, _ = hunyuan3d_sde_step_with_logprob(
            scheduler=scheduler_ode,
            model_output=model_output,
            timestep=timestep,
            sample=sample,
            generator=generator_ode,
            deterministic=True,
        )
        
        # è¿è¡Œ SDE å¤šæ¬¡
        num_runs = 50
        sde_results = []
        
        for j in range(num_runs):
            # ğŸ”§ ä¿®å¤ï¼šæ¯æ¬¡è¿è¡Œéƒ½ä½¿ç”¨æ–°çš„scheduleré¿å…çŠ¶æ€æ±¡æŸ“
            scheduler_sde = create_test_scheduler()
            generator_sde = torch.Generator(device=device).manual_seed(42 + j)
            sde_result, _, _, _ = hunyuan3d_sde_step_with_logprob(
                scheduler=scheduler_sde,
                model_output=model_output,
                timestep=timestep,
                sample=sample,
                generator=generator_sde,
                deterministic=False,
            )
            sde_results.append(sde_result)
        
        # è®¡ç®— SDE å‡å€¼
        sde_results_tensor = torch.stack(sde_results)
        sde_mean = sde_results_tensor.mean(dim=0)
        
        # æ¯”è¾ƒ
        diff = torch.abs(sde_mean - ode_result).max().item()
        
        print(f"  ODE vs SDE å‡å€¼å·®å¼‚: {diff:.8f}")
        
        # åˆ¤æ–­æ˜¯å¦é€šè¿‡
        tolerance = 1e-3
        passed = diff < tolerance
        results.append(passed)
        
        if passed:
            print(f"  âœ… PASS: æ—¶é—´æ­¥ {timestep} æµ‹è¯•é€šè¿‡")
        else:
            print(f"  âŒ FAIL: æ—¶é—´æ­¥ {timestep} æµ‹è¯•å¤±è´¥")
    
    # æ€»ç»“
    all_passed = all(results)
    print(f"\nğŸ¯ è·¨æ—¶é—´æ­¥ä¸€è‡´æ€§æ€»ç»“:")
    print(f"  é€šè¿‡çš„æ—¶é—´æ­¥: {sum(results)}/{len(results)}")
    
    if all_passed:
        print(f"  âœ… PASS: æ‰€æœ‰æ—¶é—´æ­¥æµ‹è¯•é€šè¿‡")
    else:
        print(f"  âŒ FAIL: éƒ¨åˆ†æ—¶é—´æ­¥æµ‹è¯•å¤±è´¥")
    
    return all_passed


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ SDE deterministic=False ä¸€è‡´æ€§æµ‹è¯•")
    print("=" * 80)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_functions = [
        test_sde_mean_equals_ode,
        test_sde_variance_theory,
        test_sde_distribution_shape,
        test_consistency_across_timesteps,
    ]
    
    results = []
    
    for test_func in test_functions:
        try:
            result = test_func()
            results.append(result)
            print(f"\n{'='*50}")
        except Exception as e:
            print(f"\nâŒ æµ‹è¯• {test_func.__name__} å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results.append(False)
    
    # æ€»ç»“
    print(f"\n{'='*80}")
    print("ğŸ¯ æœ€ç»ˆæµ‹è¯•ç»“æœ")
    print(f"{'='*80}")
    
    test_names = [
        "SDE å‡å€¼ = ODE ç»“æœ",
        "SDE æ–¹å·®ç†è®ºéªŒè¯",
        "SDE åˆ†å¸ƒå½¢çŠ¶éªŒè¯",
        "è·¨æ—¶é—´æ­¥ä¸€è‡´æ€§",
    ]
    
    for i, (name, result) in enumerate(zip(test_names, results)):
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {i+1}. {name}: {status}")
    
    passed = sum(results)
    total = len(results)
    
    print(f"\nğŸ“Š æ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼SDE deterministic=False å®ç°æ­£ç¡®ã€‚")
        return 0
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ SDE å®ç°ã€‚")
        return 1


if __name__ == "__main__":
    exit(main()) 