#!/usr/bin/env python3
"""
ä½¿ç”¨å‚è€ƒä»£ç çš„æ ‡å‡†æ–¹æ³•æµ‹è¯•
å¯¹æ¯”è‡ªå®šä¹‰SDEå®žçŽ°å’Œæ ‡å‡†scheduler.stepæ–¹æ³•çš„å·®å¼‚
"""

import os
import sys
import torch
import numpy as np
from PIL import Image
import time
from tqdm import tqdm

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from generators.hunyuan3d.pipeline import Hunyuan3DPipeline
from generators.hunyuan3d.hy3dshape.pipelines import retrieve_timesteps


def test_reference_method():
    """ä½¿ç”¨å‚è€ƒä»£ç çš„æ ‡å‡†æ–¹æ³•æµ‹è¯•"""
    print("ðŸ§ª ä½¿ç”¨å‚è€ƒä»£ç çš„æ ‡å‡†æ–¹æ³•æµ‹è¯•")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–Pipeline
    print("\nðŸŽ¯ æ­¥éª¤ 1: åˆå§‹åŒ–Pipeline")
    try:
        wrapper_pipeline = Hunyuan3DPipeline()
        pipeline = wrapper_pipeline.core_pipeline
        print("  âœ… Pipeline åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"  âŒ Pipeline åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # 2. åŠ è½½æµ‹è¯•å›¾åƒ
    print("\nðŸŽ¯ æ­¥éª¤ 2: åŠ è½½æµ‹è¯•å›¾åƒ")
    test_image_path = "dataset/eval3d/images/walking_siamese_cat.png"
    
    if not os.path.exists(test_image_path):
        print(f"  âŒ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image_path}")
        return False
    
    image = Image.open(test_image_path).convert("RGBA")
    print(f"  âœ… æˆåŠŸåŠ è½½å›¾åƒ: {test_image_path}")
    
    # 3. ä½¿ç”¨å‚è€ƒä»£ç çš„æ ‡å‡†æ–¹æ³•
    print("\nðŸŽ¯ æ­¥éª¤ 3: ä½¿ç”¨å‚è€ƒä»£ç çš„æ ‡å‡†æ–¹æ³•")
    
    # å‚è€ƒä»£ç çš„å‚æ•°
    num_inference_steps = 50
    guidance_scale = 5.0
    octree_resolution = 384
    mc_level = 0.0
    num_chunks = 8000
    
    device = pipeline.device
    dtype = pipeline.dtype
    
    # ðŸ”§ å…³é”®ï¼šä½¿ç”¨å‚è€ƒä»£ç çš„æ¡ä»¶å¤„ç†æ–¹å¼
    do_classifier_free_guidance = guidance_scale >= 0 and not (
        hasattr(pipeline.model, 'guidance_embed') and
        pipeline.model.guidance_embed is True
    )
    
    cond_inputs = pipeline.prepare_image(image)
    image_tensor = cond_inputs.pop('image')
    cond = pipeline.encode_cond(
        image=image_tensor,
        additional_cond_inputs=cond_inputs,
        do_classifier_free_guidance=do_classifier_free_guidance,
        dual_guidance=False,
    )
    
    batch_size = image_tensor.shape[0]
    
    # ðŸ”§ å…³é”®ï¼šä½¿ç”¨å‚è€ƒä»£ç çš„timestepså¤„ç†
    sigmas = np.linspace(0, 1, num_inference_steps)
    timesteps, num_inference_steps = retrieve_timesteps(
        pipeline.scheduler,
        num_inference_steps,
        device,
        sigmas=sigmas,
    )
    
    latents = pipeline.prepare_latents(batch_size, dtype, device, torch.Generator().manual_seed(42))
    
    # ðŸ”§ å…³é”®ï¼šä½¿ç”¨å‚è€ƒä»£ç çš„guidanceå¤„ç†
    guidance = None
    if hasattr(pipeline.model, 'guidance_embed') and pipeline.model.guidance_embed is True:
        guidance = torch.tensor([guidance_scale] * batch_size, device=device, dtype=dtype)
    
    print(f"  ðŸ“Š åˆå§‹latentsèŒƒå›´: [{latents.min():.6f}, {latents.max():.6f}]")
    
    # 4. ä½¿ç”¨æ ‡å‡†çš„scheduler.stepæ–¹æ³•è¿›è¡Œæ‰©æ•£é‡‡æ ·
    print("\nðŸŽ¯ æ­¥éª¤ 4: ä½¿ç”¨æ ‡å‡†çš„scheduler.stepæ–¹æ³•")
    
    start_time = time.time()
    
    for i, t in enumerate(tqdm(timesteps, desc="æ ‡å‡†æ–¹æ³•æ‰©æ•£é‡‡æ ·")):
        # ðŸ”§ å…³é”®ï¼šå®Œå…¨æŒ‰ç…§å‚è€ƒä»£ç çš„æ–¹å¼
        if do_classifier_free_guidance:
            latent_model_input = torch.cat([latents] * 2)
        else:
            latent_model_input = latents
        
        # ðŸ”§ å…³é”®ï¼šæŒ‰ç…§å‚è€ƒä»£ç çš„timestepå¤„ç†
        timestep = t.expand(latent_model_input.shape[0]).to(latents.dtype)
        timestep = timestep / pipeline.scheduler.config.num_train_timesteps
        
        # æ¨¡åž‹é¢„æµ‹
        noise_pred = pipeline.model(latent_model_input, timestep, cond, guidance=guidance)
        
        # ðŸ”§ å…³é”®ï¼šCFGå¤„ç†
        if do_classifier_free_guidance:
            noise_pred_cond, noise_pred_uncond = noise_pred.chunk(2)
            noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_cond - noise_pred_uncond)
        
        # ðŸ”§ å…³é”®ï¼šä½¿ç”¨æ ‡å‡†çš„scheduler.stepï¼Œä¸æ˜¯è‡ªå®šä¹‰SDE
        outputs = pipeline.scheduler.step(noise_pred, t, latents)
        latents = outputs.prev_sample
        
        # æ¯10æ­¥æ‰“å°ä¸€æ¬¡çŠ¶æ€
        if (i + 1) % 10 == 0:
            print(f"    æ­¥éª¤ {i+1:2d}: latentsèŒƒå›´ [{latents.min():.6f}, {latents.max():.6f}]")
    
    end_time = time.time()
    print(f"  âœ… æ‰©æ•£é‡‡æ ·å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
    print(f"  ðŸ“Š æœ€ç»ˆlatentsèŒƒå›´: [{latents.min():.6f}, {latents.max():.6f}]")
    
    # 5. ä½¿ç”¨æ ‡å‡†çš„VAEè§£ç å’Œmeshç”Ÿæˆ
    print("\nðŸŽ¯ æ­¥éª¤ 5: ä½¿ç”¨æ ‡å‡†çš„VAEè§£ç å’Œmeshç”Ÿæˆ")
    
    # ðŸ”§ å…³é”®ï¼šå®Œå…¨æŒ‰ç…§å‚è€ƒä»£ç çš„_exportæ–¹æ³•
    latents = 1. / pipeline.vae.scale_factor * latents
    latents = pipeline.vae(latents)
    
    print(f"  ðŸ“Š VAEè§£ç åŽlatentsèŒƒå›´: [{latents.min():.6f}, {latents.max():.6f}]")
    
    # ðŸ”§ å…³é”®ï¼šæ•èŽ·grid_logits
    grid_logits = pipeline.vae.decoder(latents)
    print(f"  ðŸ“Š Grid LogitsèŒƒå›´: [{grid_logits.min():.6f}, {grid_logits.max():.6f}]")
    
    # æ£€æŸ¥æ˜¯å¦è§£å†³äº†å…¨è´Ÿå€¼é—®é¢˜
    has_positive = (grid_logits > 0).any().item()
    has_negative = (grid_logits < 0).any().item()
    
    print(f"  ðŸ” Grid Logitsåˆ†æž:")
    print(f"    åŒ…å«æ­£å€¼: {has_positive}")
    print(f"    åŒ…å«è´Ÿå€¼: {has_negative}")
    print(f"    æ•°å€¼å¥åº·: {not torch.isnan(grid_logits).any().item() and not torch.isinf(grid_logits).any().item()}")
    
    if has_positive and has_negative:
        print(f"  âœ… Grid LogitsèŒƒå›´æ­£å¸¸ï¼åŒ…å«æ­£è´Ÿå€¼")
        success = True
    else:
        print(f"  âŒ Grid LogitsèŒƒå›´å¼‚å¸¸ï¼ä»ç„¶æ˜¯å…¨æ­£æˆ–å…¨è´Ÿ")
        success = False
    
    # 6. å°è¯•ç”Ÿæˆmesh
    print("\nðŸŽ¯ æ­¥éª¤ 6: å°è¯•ç”Ÿæˆmesh")
    
    try:
        mesh_output = pipeline.vae.latents2mesh(
            latents,
            bounds=1.01,
            mc_level=mc_level,
            num_chunks=num_chunks,
            octree_resolution=octree_resolution,
            mc_algo=None,
            enable_pbar=True,
        )
        
        # è½¬æ¢ä¸ºtrimesh
        from generators.hunyuan3d.hy3dshape.pipelines import export_to_trimesh
        meshes = export_to_trimesh(mesh_output)
        mesh = meshes[0] if isinstance(meshes, list) else meshes
        
        # ä¿å­˜mesh
        output_path = "output_reference_method.obj"
        mesh.export(output_path)
        
        file_size = os.path.getsize(output_path)
        print(f"  âœ… Meshç”ŸæˆæˆåŠŸï¼")
        print(f"    æ–‡ä»¶: {output_path} ({file_size / (1024*1024):.2f} MB)")
        print(f"    é¡¶ç‚¹æ•°: {len(mesh.vertices)}")
        print(f"    é¢æ•°: {len(mesh.faces)}")
        
        # 7. æ¸²æŸ“mesh
        print("\nðŸŽ¯ æ­¥éª¤ 7: æ¸²æŸ“mesh")
        try:
            from generators.hunyuan3d.hy3dshape.utils.visualizers.renderer import simple_render_mesh
            render_output = "output_reference_method_render.png"
            simple_render_mesh(output_path, render_output)
            
            if os.path.exists(render_output):
                render_size = os.path.getsize(render_output)
                print(f"  âœ… æ¸²æŸ“æˆåŠŸ: {render_output} ({render_size / 1024:.1f} KB)")
            else:
                print(f"  âŒ æ¸²æŸ“å¤±è´¥")
                
        except Exception as e:
            print(f"  âš ï¸ æ¸²æŸ“å¤±è´¥: {e}")
        
    except Exception as e:
        print(f"  âŒ Meshç”Ÿæˆå¤±è´¥: {e}")
        success = False
        import traceback
        traceback.print_exc()
    
    print(f"\n{'='*60}")
    if success:
        print("ðŸŽ‰ æµ‹è¯•æˆåŠŸï¼æ ‡å‡†æ–¹æ³•è§£å†³äº†grid_logitsé—®é¢˜")
        print("ðŸ’¡ ç»“è®º: é—®é¢˜å‡ºåœ¨è‡ªå®šä¹‰SDEå®žçŽ°ä¸Šï¼Œæ ‡å‡†scheduler.stepæ–¹æ³•æ­£å¸¸å·¥ä½œ")
        print("ðŸ”§ å»ºè®®: ä¿®å¤æˆ–æ›¿æ¢è‡ªå®šä¹‰SDEå®žçŽ°")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼é—®é¢˜å¯èƒ½ä¸åœ¨SDEå®žçŽ°ä¸Š")
        print("ðŸ” éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥å…¶ä»–å¯èƒ½çš„åŽŸå› ")
    
    return success


def main():
    """ä¸»å‡½æ•°"""
    print("ðŸ§ª æµ‹è¯•å‚è€ƒä»£ç çš„æ ‡å‡†æ–¹æ³•")
    print("=" * 80)
    
    result = test_reference_method()
    
    if result:
        print("\nðŸŽ‰ æµ‹è¯•å®Œæˆï¼å‘çŽ°é—®é¢˜æ ¹æº")
        return 0
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥")
        return 1


if __name__ == "__main__":
    exit(main()) 