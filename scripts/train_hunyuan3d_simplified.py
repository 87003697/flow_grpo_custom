#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆHunyuan3Dè®­ç»ƒè„šæœ¬ - ä»¿ç…§SD3çš„ç®€æ´å†…å­˜ç®¡ç†

ä¸»è¦ç®€åŒ–ï¼š
1. ç§»é™¤å¤æ‚çš„è®¾å¤‡æ£€æŸ¥
2. ç®€åŒ–GPUå†…å­˜ç›‘æ§
3. ç®€åŒ–æ‰¹é‡å¤„ç†
4. ä½¿ç”¨acceleratorç»Ÿä¸€ç®¡ç†è®¾å¤‡
"""

import sys
import os
import time
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from collections import defaultdict
from concurrent import futures

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
from tqdm import tqdm
from accelerate import Accelerator
from accelerate.utils import set_seed
from accelerate.logging import get_logger

# ğŸ”§ æ·»åŠ torch.profilerç”¨äºGPUå†…å­˜åˆ†æ
from torch.profiler import profile, record_function, ProfilerActivity

# ç»Ÿä¸€é…ç½®ç®¡ç†
import ml_collections
from absl import app, flags
from ml_collections import config_flags

_CONFIG = config_flags.DEFINE_config_file("config")

# æ•°æ®å’Œæ¨¡å‹ç›¸å…³å¯¼å…¥
from generators.hunyuan3d.pipeline import Hunyuan3DPipeline
from reward_models.rewards_mesh import multi_mesh_score
from flow_grpo.trainer_3d_simplified import Hunyuan3DGRPOTrainer  # ğŸ”§ ä½¿ç”¨ç®€åŒ–ç‰ˆtrainer
from flow_grpo.ema import EMAModuleWrapper
from flow_grpo.stat_tracking import PerImageStatTracker

logger = get_logger(__name__)

# ğŸš€ ç®€åŒ–ç‰ˆGPUç›‘æ§ï¼ˆå¯é€‰ï¼‰
def simple_gpu_log(name: str):
    """ç®€å•çš„GPUå†…å­˜æ—¥å¿—ï¼Œä¸é˜»å¡è®­ç»ƒ"""
    if torch.cuda.is_available():
        memory_used = torch.cuda.memory_allocated() / 1024**3
        logger.info(f"{name}: GPUå†…å­˜ä½¿ç”¨ {memory_used:.2f}GB")

class Image3DDataset(Dataset):
    def __init__(self, image_dir: str, prompts_file: Optional[str] = None, split: str = "train"):
        self.image_dir = Path(image_dir)
        self.prompts_file = prompts_file
        self.split = split
        
        # æ£€æŸ¥å›¾åƒæ˜¯å¦åœ¨imageså­ç›®å½•ä¸­
        if (self.image_dir / "images").exists():
            self.image_dir = self.image_dir / "images"
        
        # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
        self.image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            self.image_files.extend(self.image_dir.glob(ext))
        
        self.image_files = sorted(self.image_files)
        
        if not self.image_files:
            raise ValueError(f"No images found in {self.image_dir}")
        
        logger.info(f"Found {len(self.image_files)} images in {self.image_dir}")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        image_path = str(self.image_files[idx])
        prompt = self.get_prompt(self.image_files[idx])
        
        return {
            "image_path": image_path,
            "prompt": prompt,
            "metadata": {"image_name": self.image_files[idx].name}
        }
    
    @staticmethod
    def collate_fn(examples):
        image_paths = [example["image_path"] for example in examples]
        prompts = [example["prompt"] for example in examples]
        metadata = [example["metadata"] for example in examples]
        return image_paths, prompts, metadata
    
    def get_prompt(self, image_path: Path) -> str:
        """æ ¹æ®å›¾åƒè·¯å¾„ç”Ÿæˆæç¤ºè¯"""
        return f"Generate a 3D model from this image: {image_path.stem}"

def main(argv):
    """ä¸»è®­ç»ƒå‡½æ•° - ç®€åŒ–ç‰ˆ"""
    del argv
    config = _CONFIG.value
    
    # ğŸš€ ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨acceleratorï¼Œä¸éœ€è¦å¤æ‚çš„è®¾å¤‡æ£€æŸ¥
    accelerator = Accelerator(
        mixed_precision=config.mixed_precision,
        gradient_accumulation_steps=config.train.gradient_accumulation_steps,
        log_with="wandb" if "WANDB_PROJECT" in os.environ else None,
        project_dir=config.save_dir,
    )
    
    # ğŸš€ å†…å­˜ä¼˜åŒ–ï¼šå¯ç”¨PyTorchå†…å­˜ä¼˜åŒ–ç­–ç•¥
    torch.backends.cudnn.benchmark = False  # å‡å°‘å†…å­˜ç¢ç‰‡
    torch.backends.cuda.max_split_size_mb = 128  # é™åˆ¶å†…å­˜åˆ†å‰²å¤§å°
    if hasattr(torch.backends.cuda, 'enable_flash_sdp'):
        torch.backends.cuda.enable_flash_sdp(True)  # å¯ç”¨Flash Attention
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
        datefmt="%m/%d/%Y %H:%M:%S",
        level=logging.INFO,
    )
    
    # è®¾ç½®ç§å­
    if hasattr(config, 'seed') and config.seed is not None:
        set_seed(config.seed)
    
    # ğŸš€ å†…å­˜ä¼˜åŒ–ï¼šæ¸…ç†GPUå†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()
        logger.info(f"ğŸ§¹ GPUå†…å­˜æ¸…ç†å®Œæˆï¼Œå¯ç”¨å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    
    os.makedirs(config.save_dir, exist_ok=True)
    
    # ğŸš€ ç®€åŒ–ï¼šç›´æ¥åŠ è½½æ¨¡å‹ï¼Œç»Ÿä¸€è®¾å¤‡ç®¡ç†
    logger.info("Loading Hunyuan3D pipeline...")
    pipeline_wrapper = Hunyuan3DPipeline()
    
    # ğŸš€ ç®€åŒ–ï¼šä½¿ç”¨acceleratorç»Ÿä¸€ç®¡ç†è®¾å¤‡ï¼Œä»¿ç…§SD3
    core_pipeline = pipeline_wrapper.core_pipeline
    
    # ğŸš€ ç®€åŒ–ï¼šç»Ÿä¸€è®¾å¤‡å’Œæ•°æ®ç±»å‹è®¾ç½®ï¼ˆä»¿ç…§SD3ï¼‰
    inference_dtype = torch.float32
    if accelerator.mixed_precision == "fp16":
        inference_dtype = torch.float16
    elif accelerator.mixed_precision == "bf16":
        inference_dtype = torch.bfloat16
    
    # ğŸš€ ç®€åŒ–ï¼šç›´æ¥ç§»åŠ¨åˆ°è®¾å¤‡ï¼Œä¸éœ€è¦å¤æ‚æ£€æŸ¥
    core_pipeline.vae.to(accelerator.device, dtype=torch.float32)
    core_pipeline.conditioner.to(accelerator.device, dtype=inference_dtype)
    if config.use_lora:
        core_pipeline.model.to(accelerator.device)
    else:
        core_pipeline.model.to(accelerator.device, dtype=inference_dtype)
    
    # ğŸš€ å…³é”®ä¿®å¤ï¼šæ˜¾å¼ç¦ç”¨VAEå’Œconditionerçš„æ¢¯åº¦ï¼Œè®¾ç½®evalæ¨¡å¼
    logger.info("ğŸ”§ è®¾ç½®VAEå’Œconditionerä¸ºæ¨ç†æ¨¡å¼...")
    core_pipeline.vae.eval()
    core_pipeline.conditioner.eval()
    
    # æ˜¾å¼ç¦ç”¨æ¢¯åº¦ä»¥èŠ‚çœæ˜¾å­˜
    for param in core_pipeline.vae.parameters():
        param.requires_grad = False
    for param in core_pipeline.conditioner.parameters():
        param.requires_grad = False
    
    logger.info("âœ… VAEå’Œconditioneræ¢¯åº¦å·²ç¦ç”¨ï¼Œå·²è®¾ç½®ä¸ºevalæ¨¡å¼")
    
    # ğŸš€ å†…å­˜ä¼˜åŒ–ï¼šè®­ç»ƒæ—¶å°†VAEç§»åŠ¨åˆ°CPUä»¥èŠ‚çœæ˜¾å­˜
    logger.info("ğŸš€ å†…å­˜ä¼˜åŒ–ï¼šå°†VAEç§»åŠ¨åˆ°CPUä»¥èŠ‚çœè®­ç»ƒæ˜¾å­˜...")
    core_pipeline.vae.to('cpu')
    logger.info("âœ… VAEå·²ç§»åŠ¨åˆ°CPUï¼Œæ˜¾å­˜èŠ‚çœçº¦8-12GB")
    
    # ğŸš€ ç®€åŒ–ï¼šæŒ‰ç…§SD3æ¨¡å¼è®¾ç½®LoRAå’Œprepare
    if config.use_lora:
        from peft import LoraConfig, get_peft_model
        
        lora_config = LoraConfig(
            r=32,
            lora_alpha=64,
            target_modules=[
                # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®çœŸå®æ¨¡å‹ç»“æ„è®¾ç½®target_modules
                "to_q", "to_k", "to_v", "out_proj",      # æ³¨æ„åŠ›å±‚
                "fc1", "fc2",                             # MLPå±‚
                "final_layer.linear",                     # è¾“å‡ºå±‚
                # ğŸ”§ å¯é€‰ï¼šåŠ å…¥è¾“å…¥embeddingå±‚
                "x_embedder",                             # è¾“å…¥embedding
            ],
            lora_dropout=0.1,
            bias="none",
        )
        
        core_pipeline.model = get_peft_model(core_pipeline.model, lora_config)
    
    # ğŸ”§ å…³é”®ï¼šæŒ‰ç…§SD3æ¨¡å¼ï¼Œå…ˆè·å–æ¨¡å‹å¼•ç”¨
    model = core_pipeline.model
    
    # ğŸ”§ å…³é”®ï¼šè·å–trainableå‚æ•°ï¼ˆSD3æ–¹å¼ï¼‰
    trainable_params = list(filter(lambda p: p.requires_grad, model.parameters()))
    
    # è®¾ç½®ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        trainable_params,
        lr=config.train.learning_rate,
        betas=(0.9, 0.999),
        weight_decay=0.01,
        eps=1e-8,
    )
    
    # ğŸ”§ å…³é”®ï¼šæœ€åprepareï¼ˆSD3æ–¹å¼ï¼‰
    model, optimizer = accelerator.prepare(model, optimizer)
    
    # ğŸ”§ å…³é”®ï¼šè®©core_pipelineä½¿ç”¨preparedçš„æ¨¡å‹
    core_pipeline.model = model
    
    # ğŸ”§ æŒ‰ç…§SD3æ¨¡å¼ï¼šLoRAè®­ç»ƒæ—¶ä¸ä½¿ç”¨autocast
    import contextlib
    autocast = contextlib.nullcontext if config.use_lora else accelerator.autocast
    
    # è®¾ç½®EMAï¼ˆä»¿ç…§SD3ï¼‰
    ema = None
    if config.train.ema:
        ema = EMAModuleWrapper(
            trainable_params,
            decay=config.train.ema_decay,
            device=accelerator.device
        )
    
    # ğŸš€ ç®€åŒ–ï¼šåˆ›å»ºtrainerï¼Œä¸éœ€è¦å¤æ‚çš„batch sizeé…ç½®
    reward_config = {"geometric_quality": 1.0, "uni3d": 0.0}  # ğŸš€ æ˜¾å­˜ä¼˜åŒ–ï¼šç¦ç”¨Uni3DèŠ‚çœå¤§é‡æ˜¾å­˜
    trainer = Hunyuan3DGRPOTrainer(
        pipeline=pipeline_wrapper,
        reward_config=reward_config,
        device=accelerator.device,
    )
    
    # ğŸš€ ç®€åŒ–ï¼šç›´æ¥åŠ è½½æ•°æ®é›†
    logger.info(f"Loading dataset from {config.data_dir}")
    train_dataset = Image3DDataset(config.data_dir, split="train")
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=config.sample.input_batch_size,
        shuffle=True,
        collate_fn=Image3DDataset.collate_fn,
        num_workers=0,
    )
    
    # ç»Ÿè®¡è·Ÿè¸ª
    stat_tracker = None
    if config.per_image_stat_tracking:
        stat_tracker = PerImageStatTracker(
            buffer_size=len(train_dataset),
            min_count=config.stat_tracking.min_count,
        )
    
    # è®­ç»ƒå¾ªç¯
    global_step = 0
    first_epoch = 0
    
    # ğŸ”§ å¯ç”¨torch.profilerè¿›è¡Œè¯¦ç»†çš„GPUå†…å­˜åˆ†æ
    prof_dir = "profiler_logs"
    os.makedirs(prof_dir, exist_ok=True)
    
    for epoch in range(first_epoch, config.num_epochs):
        logger.info(f"Starting epoch {epoch}")
        
        # ğŸ”§ å¼€å§‹profilingè¿™ä¸ªepoch
        with profile(
            activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
            record_shapes=True,
            profile_memory=True,  # ğŸ”§ å…³é”®ï¼šå¯ç”¨å†…å­˜profiling
            with_stack=True,
            schedule=torch.profiler.schedule(
                wait=0,
                warmup=0,
                active=1,
                repeat=1,
            ),
            on_trace_ready=torch.profiler.tensorboard_trace_handler(prof_dir),
        ) as prof:
            
            # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è¿›è¡Œé‡‡æ ·ï¼Œä¸éœ€è¦å¤æ‚çš„GPUç›‘æ§
            model.eval()
            epoch_samples = []
            
            with record_function("ğŸ” SAMPLING_PHASE"):
                simple_gpu_log(f"Epoch {epoch} - å¼€å§‹é‡‡æ ·")
                
                for batch_idx, (image_paths, prompts, metadata) in enumerate(tqdm(
                    train_dataloader, 
                    desc=f"Epoch {epoch}: sampling",
                    disable=not accelerator.is_local_main_process
                )):
                    if batch_idx >= config.sample.num_batches_per_epoch:
                        break
                    
                    with record_function(f"SAMPLE_BATCH_{batch_idx}"):
                        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥é‡‡æ ·ï¼Œä¸éœ€è¦å¤æ‚çš„å€™é€‰å¤„ç†
                        results = trainer.sample_meshes_with_rewards(
                            images=image_paths,
                            num_inference_steps=config.sample.num_steps,
                            guidance_scale=config.sample.guidance_scale,
                            deterministic=getattr(config, 'deterministic', False),
                            num_meshes_per_image=config.sample.num_meshes_per_image,  # ğŸ”§ æ·»åŠ ï¼šå¤šå€™é€‰å‚æ•°
                            kl_reward=config.sample.kl_reward,
                        )
                        
                        epoch_samples.append(results)
            
            # ğŸ”§ é‡‡æ ·å®Œæˆï¼Œè®°å½•å†…å­˜çŠ¶æ€
            simple_gpu_log(f"Epoch {epoch} - é‡‡æ ·å®Œæˆ")
            
            with record_function("ğŸ” DATA_PROCESSING_PHASE"):
                # ğŸš€ ç®€åŒ–ï¼šç›´æ¥åˆå¹¶æ ·æœ¬ï¼Œç»Ÿä¸€æ•°æ®æ ¼å¼
                all_samples = {}
                for k in epoch_samples[0].keys():
                    if k in ["meshes", "images", "prompts", "metadata"]:
                        continue
                    elif k == "rewards":
                        # ğŸ”§ ç®€åŒ–ï¼šç›´æ¥å–avgï¼Œç»Ÿä¸€ä¸ºtensoræ ¼å¼
                        all_samples[k] = torch.cat([s[k]["avg"] for s in epoch_samples], dim=0)
                    elif isinstance(epoch_samples[0][k], torch.Tensor):
                        all_samples[k] = torch.cat([s[k] for s in epoch_samples], dim=0)
                    else:
                        # ğŸ”§ ç®€åŒ–ï¼šå¯¹äºétensoræ•°æ®ï¼Œå…ˆè½¬æ¢ä¸ºtensorå†åˆå¹¶
                        if k == "kl":
                            # klç°åœ¨åº”è¯¥æ˜¯tensorï¼Œç›´æ¥åˆå¹¶
                            all_samples[k] = torch.cat([s[k] for s in epoch_samples], dim=0)
                        else:
                            # å…¶ä»–æƒ…å†µï¼Œå°è¯•è½¬æ¢ä¸ºtensor
                            all_samples[k] = torch.cat([s[k] for s in epoch_samples], dim=0)
                
                # ğŸš€ ç®€åŒ–ï¼šç›´æ¥å¤„ç†å¥–åŠ±ï¼Œç»Ÿä¸€æ ¼å¼
                rewards_avg = all_samples["rewards"]  # ç°åœ¨ç›´æ¥æ˜¯tensor
                kl_tensor = all_samples["kl"]
                
                # ğŸ”§ ç®€åŒ–ï¼šç›´æ¥è®¡ç®—KLè°ƒæ•´åçš„å¥–åŠ±
                all_samples["rewards"] = rewards_avg.unsqueeze(-1) - config.sample.kl_reward * kl_tensor
                
                # ğŸš€ ç®€åŒ–ï¼šè®©acceleratorå¤„ç†åˆ†å¸ƒå¼gather
                gathered_rewards = accelerator.gather(all_samples["rewards"])
                gathered_rewards_np = gathered_rewards.cpu().numpy()
                
                # ğŸ”§ è°ƒè¯•ï¼šæ£€æŸ¥rewardsçš„åˆ†å¸ƒ
                logger.info(f"ğŸ” è°ƒè¯• - gathered_rewardsç»Ÿè®¡:")
                logger.info(f"  shape: {gathered_rewards.shape}")
                logger.info(f"  mean: {gathered_rewards.mean().item():.6f}")
                logger.info(f"  std: {gathered_rewards.std().item():.6f}")
                logger.info(f"  min: {gathered_rewards.min().item():.6f}")
                logger.info(f"  max: {gathered_rewards.max().item():.6f}")
                
                # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è®¡ç®—advantagesï¼Œä¸éœ€è¦å¤æ‚çš„åˆ†å¸ƒå¼å¤„ç†
                if config.per_image_stat_tracking and stat_tracker:
                    all_images = [item for s in epoch_samples for item in s["images"]]
                    advantages_np = stat_tracker.update(all_images, gathered_rewards_np.mean(axis=1))
                    advantages = torch.tensor(advantages_np, device=accelerator.device)
                else:
                    advantages = gathered_rewards.mean(axis=1)  # å¹³å‡æ¯ä¸ªæ ·æœ¬çš„æ‰€æœ‰æ—¶é—´æ­¥
                    
                    # ğŸ”§ è°ƒè¯•ï¼šæ£€æŸ¥æ ‡å‡†åŒ–å‰çš„advantages
                    logger.info(f"ğŸ” è°ƒè¯• - æ ‡å‡†åŒ–å‰advantages:")
                    logger.info(f"  shape: {advantages.shape}")
                    logger.info(f"  mean: {advantages.mean().item():.6f}")
                    logger.info(f"  std: {advantages.std().item():.6f}")
                    logger.info(f"  min: {advantages.min().item():.6f}")
                    logger.info(f"  max: {advantages.max().item():.6f}")
                    
                    # ğŸ”§ ä¿®å¤ï¼šåªæœ‰åœ¨æ ‡å‡†å·®è¶³å¤Ÿå¤§æ—¶æ‰æ ‡å‡†åŒ–
                    advantages_std = advantages.std()
                    if advantages_std > 1e-8:
                        advantages = (advantages - advantages.mean()) / (advantages_std + 1e-4)
                        logger.info(f"âœ… æ ‡å‡†åŒ–å®Œæˆï¼Œstd = {advantages_std.item():.6f}")
                    else:
                        logger.warning(f"âš ï¸  æ ‡å‡†å·®è¿‡å°({advantages_std.item():.6f})ï¼Œè·³è¿‡æ ‡å‡†åŒ–")
                        advantages = advantages - advantages.mean()  # åªåšä¸­å¿ƒåŒ–
                
                # ğŸ”§ è°ƒè¯•ï¼šæ£€æŸ¥æ ‡å‡†åŒ–åçš„advantages
                logger.info(f"ğŸ” è°ƒè¯• - æ ‡å‡†åŒ–åadvantages:")
                logger.info(f"  mean: {advantages.mean().item():.6f}")
                logger.info(f"  std: {advantages.std().item():.6f}")
                logger.info(f"  min: {advantages.min().item():.6f}")
                logger.info(f"  max: {advantages.max().item():.6f}")
                
                # ğŸ”§ ç®€åŒ–ï¼šç›´æ¥æ‰©å±•advantagesåˆ°æ—¶é—´ç»´åº¦
                num_steps = all_samples["timesteps"].shape[1]
                advantages = advantages.unsqueeze(1).expand(-1, num_steps)
                all_samples["advantages"] = advantages
                
                # ğŸ”§ è°ƒè¯•ï¼šæ£€æŸ¥æ‰©å±•åçš„advantages
                logger.info(f"ğŸ” è°ƒè¯• - æ‰©å±•åadvantages:")
                logger.info(f"  shape: {advantages.shape}")
                logger.info(f"  abs().sum(dim=1): {advantages.abs().sum(dim=1)}")
                
                # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è¿‡æ»¤æ ·æœ¬ï¼Œä¸éœ€è¦å¤æ‚çš„maskå¤„ç†
                valid_mask = (advantages.abs().sum(dim=1) > 1e-6)
                logger.info(f"ğŸ” è°ƒè¯• - valid_mask: {valid_mask.sum().item()}/{len(valid_mask)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
                
                # ğŸ”§ å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ï¼Œé™ä½é˜ˆå€¼æˆ–è·³è¿‡è¿‡æ»¤
                if valid_mask.sum().item() == 0:
                    logger.warning("âš ï¸  æ‰€æœ‰æ ·æœ¬éƒ½è¢«è¿‡æ»¤æ‰äº†ï¼å°è¯•é™ä½è¿‡æ»¤é˜ˆå€¼...")
                    valid_mask = (advantages.abs().sum(dim=1) > 1e-8)
                    logger.info(f"ğŸ” é™ä½é˜ˆå€¼å: {valid_mask.sum().item()}/{len(valid_mask)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
                    
                    if valid_mask.sum().item() == 0:
                        logger.warning("âš ï¸  ä»ç„¶æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ï¼è·³è¿‡è¿‡æ»¤ï¼Œä½¿ç”¨æ‰€æœ‰æ ·æœ¬...")
                        valid_mask = torch.ones(len(advantages), dtype=torch.bool, device=advantages.device)
                
                # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨çš„æ ·æœ¬è¿‡æ»¤ï¼Œå¤„ç†å½¢çŠ¶ä¸åŒ¹é…
                for key in all_samples.keys():
                    if isinstance(all_samples[key], torch.Tensor):
                        # æ£€æŸ¥tensorç»´åº¦æ˜¯å¦ä¸valid_maskåŒ¹é…
                        if all_samples[key].shape[0] == valid_mask.shape[0]:
                            all_samples[key] = all_samples[key][valid_mask]
                        else:
                            print(f"âš ï¸  è·³è¿‡è¿‡æ»¤ {key}: shape {all_samples[key].shape} vs mask {valid_mask.shape}")
                    else:
                        print(f"âš ï¸  è·³è¿‡étensorç±»å‹ {key}: {type(all_samples[key])}")
                
                logger.info(f"Training on {valid_mask.sum().item()} samples")
                
                # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿è®­ç»ƒæ—¶æŒ‰ç…§config.train.batch_sizeåˆ‡åˆ†æ•°æ®
                if "latents" in all_samples:
                    latents = all_samples["latents"]
                    if isinstance(latents, list):
                        # å¦‚æœæ˜¯åˆ—è¡¨,å…ˆè½¬æ¢ä¸ºtensor
                        latents = torch.stack(latents, dim=1)  # [B, T, ...]
                    all_samples["latents"] = latents[:, :-1]
                    all_samples["next_latents"] = latents[:, 1:]
                
                # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†æ•°æ®åˆ‡åˆ†ä¸ºç¬¦åˆtrain.batch_sizeçš„å°æ‰¹æ¬¡
                total_samples = all_samples["latents"].shape[0]
                train_batch_size = config.train.batch_size
                
                if total_samples > train_batch_size:
                    # åªå–å‰train_batch_sizeä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒ
                    for key in all_samples.keys():
                        if isinstance(all_samples[key], torch.Tensor):
                            # æ£€æŸ¥tensorç»´åº¦æ˜¯å¦ä¸total_samplesåŒ¹é…
                            if all_samples[key].shape[0] == total_samples:
                                all_samples[key] = all_samples[key][:train_batch_size]
                                logger.info(f"ğŸ”§ åˆ‡åˆ† {key}: {total_samples} â†’ {train_batch_size}")
                            elif key == "positive_image_cond":
                                # ç‰¹æ®Šå¤„ç†positive_image_condï¼šå®ƒå¯èƒ½æœ‰ä¸åŒçš„batch sizeä½†ä»éœ€è¦åˆ‡åˆ†
                                if all_samples[key].shape[0] >= train_batch_size:
                                    all_samples[key] = all_samples[key][:train_batch_size]
                                    logger.info(f"ğŸ”§ åˆ‡åˆ† {key}: {all_samples[key].shape[0]} â†’ {train_batch_size}")
                                else:
                                    # å¦‚æœpositive_image_condçš„batch sizeå°äºtrain_batch_sizeï¼Œé‡å¤å®ƒ
                                    repeat_factor = train_batch_size // all_samples[key].shape[0]
                                    remainder = train_batch_size % all_samples[key].shape[0]
                                    repeated_cond = all_samples[key].repeat(repeat_factor, 1, 1, 1)
                                    if remainder > 0:
                                        repeated_cond = torch.cat([repeated_cond, all_samples[key][:remainder]], dim=0)
                                    all_samples[key] = repeated_cond
                                    logger.info(f"ğŸ”§ æ‰©å±• {key}: {all_samples[key].shape[0]} â†’ {train_batch_size}")
                            else:
                                logger.info(f"âš ï¸  è·³è¿‡åˆ‡åˆ† {key}: shape {all_samples[key].shape} vs total_samples {total_samples}")
                        else:
                            logger.info(f"âš ï¸  è·³è¿‡étensorç±»å‹ {key}: {type(all_samples[key])}")
                    
                    logger.info(f"ğŸ”§ æ•°æ®åˆ‡åˆ†ï¼šä»{total_samples}ä¸ªæ ·æœ¬åˆ‡åˆ†ä¸º{train_batch_size}ä¸ªæ ·æœ¬ç”¨äºè®­ç»ƒ")
            
            # ğŸ”§ æ•°æ®å¤„ç†å®Œæˆï¼Œè®°å½•å†…å­˜çŠ¶æ€
            simple_gpu_log(f"Epoch {epoch} - æ•°æ®å¤„ç†å®Œæˆ")
            
            # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è®­ç»ƒï¼ˆä»¿ç…§SD3ï¼‰
            with record_function("ğŸ” TRAINING_PHASE"):
                for inner_epoch in range(config.train.num_inner_epochs):
                    model.train()
                    
                    # ğŸš€ å†…å­˜ä¼˜åŒ–ï¼šè®­ç»ƒå‰æ¸…ç†GPUå†…å­˜
                    torch.cuda.empty_cache()
                    simple_gpu_log(f"è®­ç»ƒå‰å†…å­˜æ¸…ç†")
                    
                    with record_function("âš ï¸  CRITICAL_TRAIN_STEP"):
                        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨trainerè®­ç»ƒï¼ˆè¿™é‡Œä¼šOOMï¼‰
                        loss_info = trainer.train_step(
                            samples=all_samples,
                            pipeline=core_pipeline,
                            optimizer=optimizer,
                            config=config,
                            accelerator=accelerator,
                            autocast=autocast,  # ğŸ”§ ä¼ å…¥autocastå‡½æ•°
                        )
                    
                    # æ›´æ–°EMA
                    if ema is not None:
                        ema.update()
            
            # ğŸ”§ è®­ç»ƒå®Œæˆï¼Œè®°å½•å†…å­˜çŠ¶æ€
            simple_gpu_log(f"Epoch {epoch} - è®­ç»ƒå®Œæˆ")
            
            prof.step()  # ğŸ”§ profiler step
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥è®°å½•æ—¥å¿—
        accelerator.log({
            "epoch": epoch,
            "reward_avg": gathered_rewards_np.mean(),
            "kl": all_samples["kl"].mean().cpu().numpy(),
            "advantages": advantages.mean().cpu().numpy(),
        }, step=global_step)
        
        global_step += 1
        
        # ğŸš€ ç®€åŒ–ï¼šç›´æ¥ä¿å­˜æ£€æŸ¥ç‚¹
        if epoch % config.save_freq == 0:
            save_dir = os.path.join(config.save_dir, f"checkpoint_{epoch}")
            os.makedirs(save_dir, exist_ok=True)
            
            # ä¿å­˜æ¨¡å‹
            model_to_save = accelerator.unwrap_model(model)
            torch.save(model_to_save.state_dict(), os.path.join(save_dir, "model.pt"))
            
            logger.info(f"Saved checkpoint to {save_dir}")
        
        simple_gpu_log(f"Epoch {epoch} - å®Œæˆ")
    
    # ğŸ”§ ä¿å­˜profileræŠ¥å‘Š
    logger.info(f"ğŸ” Profileræ—¥å¿—ä¿å­˜åœ¨: {prof_dir}")
    logger.info("ğŸ“Š æŸ¥çœ‹æ–¹æ³•: tensorboard --logdir profiler_logs")

if __name__ == "__main__":
    app.run(main) 