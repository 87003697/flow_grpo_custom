#!/usr/bin/env python3

import os
import sys
import torch
import numpy as np
from pathlib import Path
import trimesh

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

from reward_models.uni3d_scorer.uni3d_scorer import Uni3DScorer
from reward_models.uni3d_scorer.models.mesh_utils import Mesh

def load_glb_as_mesh(mesh_path):
    """åŠ è½½GLBæ–‡ä»¶ä¸ºMeshå¯¹è±¡"""
    scene = trimesh.load(mesh_path, force='scene')
    geometry = list(scene.geometry.values())[0]
    
    mesh = Mesh()
    mesh.v = geometry.vertices
    mesh.f = geometry.faces
    if hasattr(geometry.visual, 'vertex_colors'):
        mesh.vc = geometry.visual.vertex_colors[:, :3] / 255.0
    else:
        mesh.vc = None
    
    return mesh

def test_recall_at_1():
    """æµ‹è¯•ç®€åŒ–åçš„uni3d_scoreråœ¨5ä¸ªç‰¹å®šæ ·æœ¬ä¸Šçš„recall@1"""
    
    # æµ‹è¯•æ•°æ®
    samples = [
        "dancing_patrick_star",
        "flying_ironman", 
        "scaring_skull",
        "walking_siamese_cat",
        "firing_pistol"
    ]
    
    print("ğŸ§ª æµ‹è¯•ç®€åŒ–åçš„uni3d_scorer - Recall@1")
    print("=" * 50)
    
    # åˆå§‹åŒ–è¯„åˆ†å™¨
    scorer = Uni3DScorer()
    
    # å‡†å¤‡æ•°æ®
    images = []
    meshes = []
    
    for sample in samples:
        image_path = f"dataset/eval3d/images/{sample}.png"
        mesh_path = f"dataset/eval3d/meshes/{sample}_textured_frame_000000.glb"
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            continue
        if not os.path.exists(mesh_path):
            print(f"âŒ Meshæ–‡ä»¶ä¸å­˜åœ¨: {mesh_path}")
            continue
            
        images.append(image_path)
        mesh = load_glb_as_mesh(mesh_path)
        meshes.append(mesh)
        print(f"âœ… åŠ è½½æ ·æœ¬: {sample}")
    
    if len(images) != len(samples):
        print(f"âš ï¸ åªæ‰¾åˆ° {len(images)}/{len(samples)} ä¸ªæ ·æœ¬")
    
    if len(images) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆæ ·æœ¬ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    # æ‰¹é‡è¯„åˆ†
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡è¯„åˆ† {len(images)} ä¸ªæ ·æœ¬...")
    scores, metadata = scorer(meshes, images)
    
    print(f"\nğŸ“Š è¯„åˆ†ç»“æœ:")
    for i, (sample, score) in enumerate(zip(samples[:len(scores)], scores)):
        print(f"  {sample}: {score:.4f}")
    
    # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    print(f"\nğŸ”„ è®¡ç®—å®Œæ•´ç›¸ä¼¼åº¦çŸ©é˜µ...")
    
    # æ‰€æœ‰å›¾åƒvsæ‰€æœ‰meshçš„ç›¸ä¼¼åº¦çŸ©é˜µ
    all_scores = []
    for i, image in enumerate(images):
        row_scores, _ = scorer(meshes, [image] * len(meshes))
        all_scores.append(row_scores)
        print(f"  å›¾åƒ {i+1} vs æ‰€æœ‰mesh: {[f'{s:.3f}' for s in row_scores]}")
    
    similarity_matrix = np.array(all_scores)
    
    # è®¡ç®—Recall@1
    correct_matches = 0
    total_queries = len(images)
    
    print(f"\nğŸ¯ Recall@1 åˆ†æ:")
    for i in range(total_queries):
        # æ¯è¡Œæ‰¾æœ€é«˜åˆ†çš„ç´¢å¼•
        predicted_idx = np.argmax(similarity_matrix[i])
        ground_truth_idx = i  # å¯¹è§’çº¿ä¸ºæ­£ç¡®åŒ¹é…
        
        is_correct = predicted_idx == ground_truth_idx
        if is_correct:
            correct_matches += 1
            
        print(f"  æŸ¥è¯¢ {i+1} ({samples[i]}): "
              f"é¢„æµ‹={predicted_idx+1} ({'âœ…' if is_correct else 'âŒ'})")
    
    recall_at_1 = correct_matches / total_queries
    print(f"\nğŸ† æœ€ç»ˆç»“æœ:")
    print(f"  æ­£ç¡®åŒ¹é…: {correct_matches}/{total_queries}")
    print(f"  Recall@1: {recall_at_1:.1%}")
    
    if recall_at_1 == 1.0:
        print("ğŸ‰ å®Œç¾ï¼uni3d_scorerè¾¾åˆ°100%æ€§èƒ½ï¼")
    elif recall_at_1 > 0.8:
        print("âœ… æ€§èƒ½è‰¯å¥½ï¼Œuni3d_scoreræ•ˆæœä¸é”™")
    else:
        print("âš ï¸ æ€§èƒ½è¾ƒä½ï¼Œéœ€è¦æ£€æŸ¥é…ç½®æˆ–æ•°æ®")

if __name__ == "__main__":
    test_recall_at_1() 