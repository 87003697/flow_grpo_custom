#!/usr/bin/env python3
"""
PyTorch RMSNorm å…¼å®¹æ€§è¡¥ä¸
ä¸ºPyTorch 2.2.1ç­‰è€ç‰ˆæœ¬æä¾›RMSNormæ”¯æŒ
"""
import torch
import torch.nn as nn
import math

def apply_rmsnorm_patch():
    """ä¸ºè€ç‰ˆæœ¬PyTorchæ·»åŠ RMSNormæ”¯æŒ"""
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰RMSNorm
    if hasattr(torch.nn, 'RMSNorm'):
        print("âœ… PyTorchå·²æœ‰åŸç”ŸRMSNormï¼Œæ— éœ€è¡¥ä¸")
        return
    
    print("ğŸ”§ ä¸ºPyTorchæ·»åŠ RMSNormå…¼å®¹æ€§è¡¥ä¸...")
    
    class RMSNorm(nn.Module):
        """
        Root Mean Square Layer Normalizationçš„å…¼å®¹å®ç°
        å‚è€ƒ: https://arxiv.org/abs/1910.07467
        """
        def __init__(self, normalized_shape, eps=None, elementwise_affine=True, device=None, dtype=None):
            super().__init__()
            
            if isinstance(normalized_shape, int):
                normalized_shape = (normalized_shape,)
            self.normalized_shape = tuple(normalized_shape)
            
            if eps is None:
                eps = torch.finfo(torch.float32).eps
            self.eps = eps
            self.elementwise_affine = elementwise_affine
            
            if self.elementwise_affine:
                self.weight = nn.Parameter(torch.ones(normalized_shape, device=device, dtype=dtype))
            else:
                self.register_parameter('weight', None)
                
        def forward(self, x):
            # è®¡ç®—RMS: sqrt(mean(x^2) + eps)
            norm_dims = tuple(range(x.dim() - len(self.normalized_shape), x.dim()))
            rms = torch.sqrt(torch.mean(x.pow(2), dim=norm_dims, keepdim=True) + self.eps)
            
            # å½’ä¸€åŒ–
            x_normed = x / rms
            
            # å¦‚æœæœ‰å¯å­¦ä¹ å‚æ•°ï¼Œåº”ç”¨ç¼©æ”¾
            if self.elementwise_affine:
                x_normed = x_normed * self.weight
                
            return x_normed
        
        def extra_repr(self):
            return f'{self.normalized_shape}, eps={self.eps}, elementwise_affine={self.elementwise_affine}'
        
        def reset_parameters(self):
            if self.elementwise_affine:
                nn.init.ones_(self.weight)
    
    # å°†RMSNormæ·»åŠ åˆ°torch.nn
    torch.nn.RMSNorm = RMSNorm
    
    # åŒæ—¶æ·»åŠ åˆ°torch.nn.modules.normalizationï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
    if hasattr(torch.nn, 'modules') and hasattr(torch.nn.modules, 'normalization'):
        torch.nn.modules.normalization.RMSNorm = RMSNorm
    
    print("âœ… RMSNormè¡¥ä¸åº”ç”¨æˆåŠŸï¼")

if __name__ == "__main__":
    # æµ‹è¯•è¡¥ä¸
    apply_rmsnorm_patch()
    
    # ç®€å•æµ‹è¯•
    try:
        rms_norm = torch.nn.RMSNorm([2, 3])
        input_tensor = torch.randn(2, 2, 3)
        output = rms_norm(input_tensor)
        print(f"ğŸ¯ æµ‹è¯•æˆåŠŸï¼è¾“å…¥shape: {input_tensor.shape}, è¾“å‡ºshape: {output.shape}")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}") 