# Hunyuan 3D is licensed under the TENCENT HUNYUAN NON-COMMERCIAL LICENSE AGREEMENT
# except for the third-party components listed below.
# Hunyuan 3D does not impose any additional limitations beyond what is outlined
# in the repsective licenses of these third-party components.
# Users must comply with all terms and conditions of original licenses of these third-party
# components and must ensure that the usage of the third party components adheres to
# all relevant laws and regulations.

# For avoidance of doubts, Hunyuan 3D means the large language models and
# their software and algorithms, including trained model weights, parameters (including
# optimizer states), machine-learning model code, inference-enabling code, training-enabling code,
# fine-tuning enabling code and other elements of the foregoing made publicly available
# by Tencent in accordance with TENCENT HUNYUAN COMMUNITY LICENSE AGREEMENT.

from typing import Union, Tuple, List, Callable

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from einops import repeat
from tqdm import tqdm

from .attention_blocks import CrossAttentionDecoder
from .attention_processors import FlashVDMCrossAttentionProcessor, FlashVDMTopMCrossAttentionProcessor
from ...utils import logger


def extract_near_surface_volume_fn(input_tensor: torch.Tensor, alpha: float):
    device = input_tensor.device
    D = input_tensor.shape[0]
    signed_val = 0.0

    # æ·»åŠ åç§»å¹¶å¤„ç†æ— æ•ˆå€¼
    val = input_tensor + alpha
    valid_mask = val > -9000  # å‡è®¾-9000æ˜¯æ— æ•ˆå€¼

    # æ”¹è¿›çš„é‚»å±…è·å–å‡½æ•°ï¼ˆä¿æŒç»´åº¦ä¸€è‡´ï¼‰
    def get_neighbor(t, shift, axis):
        """æ ¹æ®æŒ‡å®šè½´è¿›è¡Œä½ç§»å¹¶ä¿æŒç»´åº¦ä¸€è‡´"""
        if shift == 0:
            return t.clone()

        # ç¡®å®šå¡«å……è½´ï¼ˆè¾“å…¥ä¸º[D, D, D]å¯¹åº”z,y,xè½´ï¼‰
        pad_dims = [0, 0, 0, 0, 0, 0]  # æ ¼å¼ï¼š[xå‰ï¼Œxåï¼Œyå‰ï¼Œyåï¼Œzå‰ï¼Œzå]

        # æ ¹æ®è½´ç±»å‹è®¾ç½®å¡«å……
        if axis == 0:  # xè½´ï¼ˆæœ€åä¸€ä¸ªç»´åº¦ï¼‰
            pad_idx = 0 if shift > 0 else 1
            pad_dims[pad_idx] = abs(shift)
        elif axis == 1:  # yè½´ï¼ˆä¸­é—´ç»´åº¦ï¼‰
            pad_idx = 2 if shift > 0 else 3
            pad_dims[pad_idx] = abs(shift)
        elif axis == 2:  # zè½´ï¼ˆç¬¬ä¸€ä¸ªç»´åº¦ï¼‰
            pad_idx = 4 if shift > 0 else 5
            pad_dims[pad_idx] = abs(shift)

        # æ‰§è¡Œå¡«å……ï¼ˆæ·»åŠ batchå’Œchannelç»´åº¦é€‚é…F.padï¼‰
        padded = F.pad(t.unsqueeze(0).unsqueeze(0), pad_dims[::-1], mode='replicate')  # åè½¬é¡ºåºé€‚é…F.pad

        # æ„å»ºåŠ¨æ€åˆ‡ç‰‡ç´¢å¼•
        slice_dims = [slice(None)] * 3  # åˆå§‹åŒ–ä¸ºå…¨åˆ‡ç‰‡
        if axis == 0:  # xè½´ï¼ˆdim=2ï¼‰
            if shift > 0:
                slice_dims[0] = slice(shift, None)
            else:
                slice_dims[0] = slice(None, shift)
        elif axis == 1:  # yè½´ï¼ˆdim=1ï¼‰
            if shift > 0:
                slice_dims[1] = slice(shift, None)
            else:
                slice_dims[1] = slice(None, shift)
        elif axis == 2:  # zè½´ï¼ˆdim=0ï¼‰
            if shift > 0:
                slice_dims[2] = slice(shift, None)
            else:
                slice_dims[2] = slice(None, shift)

        # åº”ç”¨åˆ‡ç‰‡å¹¶æ¢å¤ç»´åº¦
        padded = padded.squeeze(0).squeeze(0)
        sliced = padded[slice_dims]
        return sliced

    # è·å–å„æ–¹å‘é‚»å±…ï¼ˆç¡®ä¿ç»´åº¦ä¸€è‡´ï¼‰
    left = get_neighbor(val, 1, axis=0)  # xæ–¹å‘
    right = get_neighbor(val, -1, axis=0)
    back = get_neighbor(val, 1, axis=1)  # yæ–¹å‘
    front = get_neighbor(val, -1, axis=1)
    down = get_neighbor(val, 1, axis=2)  # zæ–¹å‘
    up = get_neighbor(val, -1, axis=2)

    # å¤„ç†è¾¹ç•Œæ— æ•ˆå€¼ï¼ˆä½¿ç”¨whereä¿æŒç»´åº¦ä¸€è‡´ï¼‰
    def safe_where(neighbor):
        return torch.where(neighbor > -9000, neighbor, val)

    left = safe_where(left)
    right = safe_where(right)
    back = safe_where(back)
    front = safe_where(front)
    down = safe_where(down)
    up = safe_where(up)

    # è®¡ç®—ç¬¦å·ä¸€è‡´æ€§ï¼ˆè½¬æ¢ä¸ºfloat32ç¡®ä¿ç²¾åº¦ï¼‰
    sign = torch.sign(val.to(torch.float32))
    neighbors_sign = torch.stack([
        torch.sign(left.to(torch.float32)),
        torch.sign(right.to(torch.float32)),
        torch.sign(back.to(torch.float32)),
        torch.sign(front.to(torch.float32)),
        torch.sign(down.to(torch.float32)),
        torch.sign(up.to(torch.float32))
    ], dim=0)

    # æ£€æŸ¥æ‰€æœ‰ç¬¦å·æ˜¯å¦ä¸€è‡´
    same_sign = torch.all(neighbors_sign == sign, dim=0)

    # ç”Ÿæˆæœ€ç»ˆæ©ç 
    mask = (~same_sign).to(torch.int32)
    return mask * valid_mask.to(torch.int32)


def generate_dense_grid_points(
    bbox_min: np.ndarray,
    bbox_max: np.ndarray,
    octree_resolution: int,
    indexing: str = "ij",
):
    length = bbox_max - bbox_min
    num_cells = octree_resolution

    x = np.linspace(bbox_min[0], bbox_max[0], int(num_cells) + 1, dtype=np.float32)
    y = np.linspace(bbox_min[1], bbox_max[1], int(num_cells) + 1, dtype=np.float32)
    z = np.linspace(bbox_min[2], bbox_max[2], int(num_cells) + 1, dtype=np.float32)
    [xs, ys, zs] = np.meshgrid(x, y, z, indexing=indexing)
    xyz = np.stack((xs, ys, zs), axis=-1)
    grid_size = [int(num_cells) + 1, int(num_cells) + 1, int(num_cells) + 1]

    return xyz, grid_size, length


class VanillaVolumeDecoder:
    @torch.no_grad()
    def __call__(
        self,
        latents: torch.FloatTensor,
        geo_decoder: Callable,
        bounds: Union[Tuple[float], List[float], float] = 1.01,
        num_chunks: int = 10000,
        octree_resolution: int = None,
        enable_pbar: bool = True,
        **kwargs,
    ):
        device = latents.device
        dtype = latents.dtype
        batch_size = latents.shape[0]

        # 1. generate query points
        if isinstance(bounds, float):
            bounds = [-bounds, -bounds, -bounds, bounds, bounds, bounds]

        bbox_min, bbox_max = np.array(bounds[0:3]), np.array(bounds[3:6])
        xyz_samples, grid_size, length = generate_dense_grid_points(
            bbox_min=bbox_min,
            bbox_max=bbox_max,
            octree_resolution=octree_resolution,
            indexing="ij"
        )
        xyz_samples = torch.from_numpy(xyz_samples).to(device, dtype=dtype).contiguous().reshape(-1, 3)

        # 2. latents to 3d volume
        batch_logits = []
        for start in tqdm(range(0, xyz_samples.shape[0], num_chunks), desc=f"Volume Decoding",
                          disable=not enable_pbar):
            chunk_queries = xyz_samples[start: start + num_chunks, :]
            chunk_queries = repeat(chunk_queries, "p c -> b p c", b=batch_size)
            logits = geo_decoder(queries=chunk_queries, latents=latents)
            batch_logits.append(logits)

        grid_logits = torch.cat(batch_logits, dim=1)
        grid_logits = grid_logits.view((batch_size, *grid_size)).float()

        return grid_logits


class HierarchicalVolumeDecoding:
    @torch.no_grad()
    def __call__(
        self,
        latents: torch.FloatTensor,
        geo_decoder: Callable,
        bounds: Union[Tuple[float], List[float], float] = 1.01,
        num_chunks: int = 10000,
        mc_level: float = 0.0,
        octree_resolution: int = None,
        min_resolution: int = 63,
        enable_pbar: bool = True,
        **kwargs,
    ):
        device = latents.device
        dtype = latents.dtype

        resolutions = []
        if octree_resolution < min_resolution:
            resolutions.append(octree_resolution)
        while octree_resolution >= min_resolution:
            resolutions.append(octree_resolution)
            octree_resolution = octree_resolution // 2
        resolutions.reverse()

        # 1. generate query points
        if isinstance(bounds, float):
            bounds = [-bounds, -bounds, -bounds, bounds, bounds, bounds]
        bbox_min = np.array(bounds[0:3])
        bbox_max = np.array(bounds[3:6])
        bbox_size = bbox_max - bbox_min

        xyz_samples, grid_size, length = generate_dense_grid_points(
            bbox_min=bbox_min,
            bbox_max=bbox_max,
            octree_resolution=resolutions[0],
            indexing="ij"
        )

        dilate = nn.Conv3d(1, 1, 3, padding=1, bias=False, device=device, dtype=dtype)
        dilate.weight = torch.nn.Parameter(torch.ones(dilate.weight.shape, dtype=dtype, device=device))

        grid_size = np.array(grid_size)
        xyz_samples = torch.from_numpy(xyz_samples).to(device, dtype=dtype).contiguous().reshape(-1, 3)

        # 2. latents to 3d volume
        batch_logits = []
        batch_size = latents.shape[0]
        for start in tqdm(range(0, xyz_samples.shape[0], num_chunks),
                          desc=f"Hierarchical Volume Decoding [r{resolutions[0] + 1}]"):
            queries = xyz_samples[start: start + num_chunks, :]
            batch_queries = repeat(queries, "p c -> b p c", b=batch_size)
            logits = geo_decoder(queries=batch_queries, latents=latents)
            batch_logits.append(logits)

        grid_logits = torch.cat(batch_logits, dim=1).view((batch_size, grid_size[0], grid_size[1], grid_size[2]))

        for octree_depth_now in resolutions[1:]:
            grid_size = np.array([octree_depth_now + 1] * 3)
            resolution = bbox_size / octree_depth_now
            next_index = torch.zeros(tuple(grid_size), dtype=dtype, device=device)
            next_logits = torch.full(next_index.shape, -10000., dtype=dtype, device=device)
            curr_points = extract_near_surface_volume_fn(grid_logits.squeeze(0), mc_level)
            curr_points += grid_logits.squeeze(0).abs() < 0.95

            if octree_depth_now == resolutions[-1]:
                expand_num = 0
            else:
                expand_num = 1
            for i in range(expand_num):
                curr_points = dilate(curr_points.unsqueeze(0).to(dtype)).squeeze(0)
            (cidx_x, cidx_y, cidx_z) = torch.where(curr_points > 0)
            next_index[cidx_x * 2, cidx_y * 2, cidx_z * 2] = 1
            for i in range(2 - expand_num):
                next_index = dilate(next_index.unsqueeze(0)).squeeze(0)
            nidx = torch.where(next_index > 0)

            next_points = torch.stack(nidx, dim=1)
            next_points = (next_points * torch.tensor(resolution, dtype=next_points.dtype, device=device) +
                           torch.tensor(bbox_min, dtype=next_points.dtype, device=device))
            batch_logits = []
            for start in tqdm(range(0, next_points.shape[0], num_chunks),
                              desc=f"Hierarchical Volume Decoding [r{octree_depth_now + 1}]"):
                queries = next_points[start: start + num_chunks, :]
                batch_queries = repeat(queries, "p c -> b p c", b=batch_size)
                logits = geo_decoder(queries=batch_queries.to(latents.dtype), latents=latents)
                batch_logits.append(logits)
            # æ™ºèƒ½å›é€€é€»è¾‘ - æ£€æŸ¥æ˜¯å¦æœ‰é‡‡æ ·ç‚¹
            if len(batch_logits) == 0:
                print(f"âš ï¸  åˆ†è¾¨ç‡ {octree_depth_now} æ²¡æœ‰æ‰¾åˆ°è¿‘è¡¨é¢ç‚¹ï¼Œåœæ­¢ç»†åŒ–å¹¶ä½¿ç”¨å½“å‰åˆ†è¾¨ç‡ç»“æœ")
                print(f"ğŸ“Š å½“å‰ç½‘æ ¼åˆ†è¾¨ç‡: {grid_logits.shape}ï¼Œè¿™å·²ç»æ˜¯å¾ˆå¥½çš„è´¨é‡äº†")
                break  # ä¼˜é›…åœ°åœæ­¢ç»†åŒ–ï¼Œä½¿ç”¨å½“å‰åˆ†è¾¨ç‡çš„ç»“æœ
            
            # æ·»åŠ é¢å¤–çš„å®‰å…¨æ£€æŸ¥
            try:
                grid_logits = torch.cat(batch_logits, dim=1)
            except RuntimeError as e:
                if "expected a non-empty list" in str(e):
                    print(f"ğŸ”§ æ£€æµ‹åˆ°ç©ºåˆ—è¡¨é”™è¯¯ï¼Œåœ¨åˆ†è¾¨ç‡ {octree_depth_now} å¤„åœæ­¢ç»†åŒ–")
                    break
                else:
                    raise e
            next_logits[nidx] = grid_logits[0, ..., 0]
            grid_logits = next_logits.unsqueeze(0)
        grid_logits[grid_logits == -10000.] = float('nan')
        
        # æ™ºèƒ½å›é€€åçš„è´¨é‡æ”¹å–„
        # å¤„ç†å¯èƒ½çš„æ•°å€¼é—®é¢˜ï¼Œç¡®ä¿è¡¨é¢æå–å™¨èƒ½æ­£å¸¸å·¥ä½œ
        if torch.isnan(grid_logits).any():
            print("âš ï¸ æ£€æµ‹åˆ°NaNå€¼ï¼Œè¿›è¡Œæ¸…ç†å¤„ç†")
            # å°†NaNæ›¿æ¢ä¸ºè¾ƒå¤§çš„è´Ÿå€¼ï¼Œè¡¨ç¤ºè¿œç¦»è¡¨é¢
            grid_logits = torch.where(torch.isnan(grid_logits), torch.tensor(-5.0, dtype=grid_logits.dtype, device=grid_logits.device), grid_logits)
        
        # ç¡®ä¿æœ‰åˆç†çš„åŠ¨æ€èŒƒå›´ç”¨äºè¡¨é¢æå–
        if grid_logits.max() - grid_logits.min() < 0.1:
            print("âš ï¸ åŠ¨æ€èŒƒå›´è¿‡å°ï¼Œè¿›è¡Œå¢å¼ºå¤„ç†")
            # å¢å¼ºåŠ¨æ€èŒƒå›´
            grid_logits = (grid_logits - grid_logits.mean()) * 2.0
        
        # ç¡®ä¿isoå€¼0.0åœ¨æ•°æ®èŒƒå›´å†…
        grid_min, grid_max = grid_logits.min(), grid_logits.max()
        if grid_min > 0.0 or grid_max < 0.0:
            print(f"âš ï¸ isoå€¼0.0ä¸åœ¨æ•°æ®èŒƒå›´å†…[{grid_min:.3f}, {grid_max:.3f}]ï¼Œè¿›è¡Œè°ƒæ•´")
            # å°†æ•°æ®èŒƒå›´è°ƒæ•´ä¸ºåŒ…å«0.0
            if grid_min > 0.0:
                # æ‰€æœ‰å€¼éƒ½æ˜¯æ­£æ•°ï¼Œå‡å»ä¸€ä¸ªåç§»é‡
                grid_logits = grid_logits - (grid_min + 0.5)
            elif grid_max < 0.0:
                # æ‰€æœ‰å€¼éƒ½æ˜¯è´Ÿæ•°ï¼ŒåŠ ä¸Šä¸€ä¸ªåç§»é‡
                grid_logits = grid_logits + (abs(grid_max) + 0.5)
        
        print(f"ğŸ“Š æœ€ç»ˆç½‘æ ¼ç»Ÿè®¡: min={grid_logits.min():.3f}, max={grid_logits.max():.3f}, mean={grid_logits.mean():.3f}")

        return grid_logits


class FlashVDMVolumeDecoding:
    def __init__(self, topk_mode='mean'):
        if topk_mode not in ['mean', 'merge']:
            raise ValueError(f'Unsupported topk_mode {topk_mode}, available: {["mean", "merge"]}')

        if topk_mode == 'mean':
            self.processor = FlashVDMCrossAttentionProcessor()
        else:
            self.processor = FlashVDMTopMCrossAttentionProcessor()

    @torch.no_grad()
    def __call__(
        self,
        latents: torch.FloatTensor,
        geo_decoder: CrossAttentionDecoder,
        bounds: Union[Tuple[float], List[float], float] = 1.01,
        num_chunks: int = 10000,
        mc_level: float = 0.0,
        octree_resolution: int = None,
        min_resolution: int = 63,
        mini_grid_num: int = 4,
        enable_pbar: bool = True,
        **kwargs,
    ):
        processor = self.processor
        geo_decoder.set_cross_attention_processor(processor)

        device = latents.device
        dtype = latents.dtype

        resolutions = []
        if octree_resolution < min_resolution:
            resolutions.append(octree_resolution)
        while octree_resolution >= min_resolution:
            resolutions.append(octree_resolution)
            octree_resolution = octree_resolution // 2
        resolutions.reverse()
        resolutions[0] = round(resolutions[0] / mini_grid_num) * mini_grid_num - 1
        for i, resolution in enumerate(resolutions[1:]):
            resolutions[i + 1] = resolutions[0] * 2 ** (i + 1)

        logger.info(f"FlashVDMVolumeDecoding Resolution: {resolutions}")

        # 1. generate query points
        if isinstance(bounds, float):
            bounds = [-bounds, -bounds, -bounds, bounds, bounds, bounds]
        bbox_min = np.array(bounds[0:3])
        bbox_max = np.array(bounds[3:6])
        bbox_size = bbox_max - bbox_min

        xyz_samples, grid_size, length = generate_dense_grid_points(
            bbox_min=bbox_min,
            bbox_max=bbox_max,
            octree_resolution=resolutions[0],
            indexing="ij"
        )

        dilate = nn.Conv3d(1, 1, 3, padding=1, bias=False, device=device, dtype=dtype)
        dilate.weight = torch.nn.Parameter(torch.ones(dilate.weight.shape, dtype=dtype, device=device))

        grid_size = np.array(grid_size)

        # 2. latents to 3d volume
        xyz_samples = torch.from_numpy(xyz_samples).to(device, dtype=dtype)
        batch_size = latents.shape[0]
        mini_grid_size = xyz_samples.shape[0] // mini_grid_num
        xyz_samples = xyz_samples.view(
            mini_grid_num, mini_grid_size,
            mini_grid_num, mini_grid_size,
            mini_grid_num, mini_grid_size, 3
        ).permute(
            0, 2, 4, 1, 3, 5, 6
        ).reshape(
            -1, mini_grid_size * mini_grid_size * mini_grid_size, 3
        )
        batch_logits = []
        num_batchs = max(num_chunks // xyz_samples.shape[1], 1)
        for start in tqdm(range(0, xyz_samples.shape[0], num_batchs),
                          desc=f"FlashVDM Volume Decoding", disable=not enable_pbar):
            queries = xyz_samples[start: start + num_batchs, :]
            batch = queries.shape[0]
            batch_latents = repeat(latents.squeeze(0), "p c -> b p c", b=batch)
            processor.topk = True
            logits = geo_decoder(queries=queries, latents=batch_latents)
            batch_logits.append(logits)
        grid_logits = torch.cat(batch_logits, dim=0).reshape(
            mini_grid_num, mini_grid_num, mini_grid_num,
            mini_grid_size, mini_grid_size,
            mini_grid_size
        ).permute(0, 3, 1, 4, 2, 5).contiguous().view(
            (batch_size, grid_size[0], grid_size[1], grid_size[2])
        )

        for octree_depth_now in resolutions[1:]:
            grid_size = np.array([octree_depth_now + 1] * 3)
            resolution = bbox_size / octree_depth_now
            next_index = torch.zeros(tuple(grid_size), dtype=dtype, device=device)
            next_logits = torch.full(next_index.shape, -10000., dtype=dtype, device=device)
            curr_points = extract_near_surface_volume_fn(grid_logits.squeeze(0), mc_level)
            curr_points += grid_logits.squeeze(0).abs() < 0.95

            if octree_depth_now == resolutions[-1]:
                expand_num = 0
            else:
                expand_num = 1
            for i in range(expand_num):
                curr_points = dilate(curr_points.unsqueeze(0).to(dtype)).squeeze(0)
            (cidx_x, cidx_y, cidx_z) = torch.where(curr_points > 0)

            next_index[cidx_x * 2, cidx_y * 2, cidx_z * 2] = 1
            for i in range(2 - expand_num):
                next_index = dilate(next_index.unsqueeze(0)).squeeze(0)
            nidx = torch.where(next_index > 0)

            next_points = torch.stack(nidx, dim=1)
            next_points = (next_points * torch.tensor(resolution, dtype=torch.float32, device=device) +
                           torch.tensor(bbox_min, dtype=torch.float32, device=device))

            query_grid_num = 6
            min_val = next_points.min(axis=0).values
            max_val = next_points.max(axis=0).values
            vol_queries_index = (next_points - min_val) / (max_val - min_val) * (query_grid_num - 0.001)
            index = torch.floor(vol_queries_index).long()
            index = index[..., 0] * (query_grid_num ** 2) + index[..., 1] * query_grid_num + index[..., 2]
            index = index.sort()
            next_points = next_points[index.indices].unsqueeze(0).contiguous()
            unique_values = torch.unique(index.values, return_counts=True)
            grid_logits = torch.zeros((next_points.shape[1]), dtype=latents.dtype, device=latents.device)
            input_grid = [[], []]
            logits_grid_list = []
            start_num = 0
            sum_num = 0
            for grid_index, count in zip(unique_values[0].cpu().tolist(), unique_values[1].cpu().tolist()):
                if sum_num + count < num_chunks or sum_num == 0:
                    sum_num += count
                    input_grid[0].append(grid_index)
                    input_grid[1].append(count)
                else:
                    processor.topk = input_grid
                    logits_grid = geo_decoder(queries=next_points[:, start_num:start_num + sum_num], latents=latents)
                    start_num = start_num + sum_num
                    logits_grid_list.append(logits_grid)
                    input_grid = [[grid_index], [count]]
                    sum_num = count
            if sum_num > 0:
                processor.topk = input_grid
                logits_grid = geo_decoder(queries=next_points[:, start_num:start_num + sum_num], latents=latents)
                logits_grid_list.append(logits_grid)
            logits_grid = torch.cat(logits_grid_list, dim=1)
            grid_logits[index.indices] = logits_grid.squeeze(0).squeeze(-1)
            next_logits[nidx] = grid_logits
            grid_logits = next_logits.unsqueeze(0)

        grid_logits[grid_logits == -10000.] = float('nan')
        
        # æ™ºèƒ½å›é€€åçš„è´¨é‡æ”¹å–„
        # å¤„ç†å¯èƒ½çš„æ•°å€¼é—®é¢˜ï¼Œç¡®ä¿è¡¨é¢æå–å™¨èƒ½æ­£å¸¸å·¥ä½œ
        if torch.isnan(grid_logits).any():
            print("âš ï¸ æ£€æµ‹åˆ°NaNå€¼ï¼Œè¿›è¡Œæ¸…ç†å¤„ç†")
            # å°†NaNæ›¿æ¢ä¸ºè¾ƒå¤§çš„è´Ÿå€¼ï¼Œè¡¨ç¤ºè¿œç¦»è¡¨é¢
            grid_logits = torch.where(torch.isnan(grid_logits), torch.tensor(-5.0, dtype=grid_logits.dtype, device=grid_logits.device), grid_logits)
        
        # ç¡®ä¿æœ‰åˆç†çš„åŠ¨æ€èŒƒå›´ç”¨äºè¡¨é¢æå–
        if grid_logits.max() - grid_logits.min() < 0.1:
            print("âš ï¸ åŠ¨æ€èŒƒå›´è¿‡å°ï¼Œè¿›è¡Œå¢å¼ºå¤„ç†")
            # å¢å¼ºåŠ¨æ€èŒƒå›´
            grid_logits = (grid_logits - grid_logits.mean()) * 2.0
        
        # ç¡®ä¿isoå€¼0.0åœ¨æ•°æ®èŒƒå›´å†…
        grid_min, grid_max = grid_logits.min(), grid_logits.max()
        if grid_min > 0.0 or grid_max < 0.0:
            print(f"âš ï¸ isoå€¼0.0ä¸åœ¨æ•°æ®èŒƒå›´å†…[{grid_min:.3f}, {grid_max:.3f}]ï¼Œè¿›è¡Œè°ƒæ•´")
            # å°†æ•°æ®èŒƒå›´è°ƒæ•´ä¸ºåŒ…å«0.0
            if grid_min > 0.0:
                # æ‰€æœ‰å€¼éƒ½æ˜¯æ­£æ•°ï¼Œå‡å»ä¸€ä¸ªåç§»é‡
                grid_logits = grid_logits - (grid_min + 0.5)
            elif grid_max < 0.0:
                # æ‰€æœ‰å€¼éƒ½æ˜¯è´Ÿæ•°ï¼ŒåŠ ä¸Šä¸€ä¸ªåç§»é‡
                grid_logits = grid_logits + (abs(grid_max) + 0.5)
        
        print(f"ğŸ“Š æœ€ç»ˆç½‘æ ¼ç»Ÿè®¡: min={grid_logits.min():.3f}, max={grid_logits.max():.3f}, mean={grid_logits.mean():.3f}")

        return grid_logits
