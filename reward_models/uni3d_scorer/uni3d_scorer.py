"""
Uni3D Scorer - ğŸš€ è¶…é«˜æ•ˆçš„3D meshè¯­ä¹‰è´¨é‡è¯„åˆ†å™¨ï¼Œä¼˜åŒ–CPU/GPU offload
"""
import torch
import torch.nn as nn
import numpy as np
import time
from typing import List, Union, Tuple
from pathlib import Path

# å¯¼å…¥æ­£ç¡®çš„æ¨¡å‹
import open_clip
from .models.uni3d import create_uni3d, Uni3D
from .models.mesh_utils import Mesh

# í—¬í¼ í•¨ìˆ˜: Farthest Point Sampling (FPS) - PyTorch êµ¬í˜„
def _fps_pytorch(xyz, npoint):
    """
    Furthest Point Sampling using PyTorch - Official Uni3D Logic
    """
    device = xyz.device
    B, N, C = xyz.shape
    
    centroids = torch.zeros(B, npoint, dtype=torch.long, device=device)
    distance = torch.ones(B, N, device=device) * 1e10
    
    farthest = torch.randint(0, N, (B,), dtype=torch.long, device=device)
    
    for i in range(npoint):
        centroids[:, i] = farthest
        centroid = xyz[torch.arange(B), farthest, :].view(B, 1, 3)
        dist = torch.sum((xyz - centroid) ** 2, -1)
        
        mask = dist < distance
        distance[mask] = dist[mask]
        farthest = torch.argmax(distance, -1)
    
    return centroids

def _gather_pytorch(points, idx):
    """
    Gather operation using PyTorch - Official Uni3D Logic
    """
    B, N, C = points.shape
    idx = idx.unsqueeze(-1).expand(-1, -1, C)
    new_points = torch.gather(points, 1, idx)
    return new_points

class Uni3DScorer:
    """ğŸš€ è¶…é«˜æ•ˆçš„Uni3Dè¯„åˆ†å™¨ï¼Œä¼˜åŒ–CPU/GPU offloadæ€§èƒ½"""
    
    def __init__(self, device="cuda", enable_dynamic_offload=True, target_device="cuda"):
        # ğŸ”§ è®¾å¤‡é…ç½®
        self.enable_dynamic_offload = enable_dynamic_offload
        self.target_device = torch.device(target_device if torch.cuda.is_available() else "cpu")
        self.cpu_device = torch.device("cpu")
        
        # ğŸ”§ æ¨¡å‹ç¼“å­˜çŠ¶æ€
        self._models_initialized = False
        self._models_on_gpu = False
        self._last_gpu_time = 0
        self._gpu_timeout = 30  # 30ç§’åè‡ªåŠ¨offload
        
        print(f"ğŸš€ FastUni3Dåˆå§‹åŒ–ï¼šenable_offload={enable_dynamic_offload}, target={target_device}")
        
        # ğŸ”§ åˆå§‹åŒ–æ¨¡å‹ï¼ˆå§‹ç»ˆåœ¨CPUä¸Šï¼ŒæŒ‰éœ€ç§»åŠ¨åˆ°GPUï¼‰
        self._init_models()
        
        # ğŸ”§ é¢„çƒ­GPU streamsä»¥åŠ é€Ÿä¼ è¾“
        if torch.cuda.is_available():
            self.stream = torch.cuda.Stream()
        else:
            self.stream = None
    
    def _init_models(self):
        """ä¸€æ¬¡æ€§åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½"""
        if self._models_initialized:
            return
            
        print("ğŸ”„ ä¸€æ¬¡æ€§åˆå§‹åŒ–Uni3Dæ¨¡å‹...")
        start_time = time.time()
        
        # ğŸ”§ å…ˆæ¸…ç†GPUç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # 1. åˆå§‹åŒ–CLIPæ¨¡å‹ - å¼ºåˆ¶æœ¬åœ°æƒé‡
        print("ğŸ”„ æ­£åœ¨åŠ è½½ CLIP æ¨¡å‹: EVA02-E-14-plus")
        clip_weights_path = Path("pretrained_weights/eva02_e_14_plus_laion2b_s9b_b144k.pt")
        if not clip_weights_path.exists():
            raise FileNotFoundError(
                f"ğŸ”¥ é”™è¯¯: CLIPæƒé‡æ–‡ä»¶æœªæ‰¾åˆ°! è¯·ç¡®ä¿ '{clip_weights_path}' å­˜åœ¨ã€‚"
            )
        print(f"ğŸ“ ä»æœ¬åœ°åŠ è½½ CLIP æƒé‡: {clip_weights_path}")
        
        # å…ˆåˆ›å»ºæ¨¡å‹æ¶æ„
        self.clip_model, _, self.clip_preprocess = open_clip.create_model_and_transforms(
            'EVA02-E-14-plus', 
            pretrained=None  # å¼ºåˆ¶ä¸ä½¿ç”¨åœ¨çº¿é¢„è®­ç»ƒæƒé‡
        )
        # åŠ è½½æœ¬åœ°æƒé‡
        state_dict = torch.load(clip_weights_path, map_location='cpu', weights_only=False)
        
        # ä¸¥æ ¼åŠ è½½CLIPæƒé‡
        try:
            missing_keys, unexpected_keys = self.clip_model.load_state_dict(state_dict, strict=True)
            print("âœ… CLIPæƒé‡ä¸¥æ ¼åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ CLIPä¸¥æ ¼åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•éä¸¥æ ¼åŠ è½½...")
            missing_keys, unexpected_keys = self.clip_model.load_state_dict(state_dict, strict=False)
            print(f"âš ï¸ ç¼ºå¤±çš„é”®: {len(missing_keys)} ä¸ª")
            print(f"âš ï¸ å¤šä½™çš„é”®: {len(unexpected_keys)} ä¸ª")
            if missing_keys:
                print(f"ç¼ºå¤±é”®ç¤ºä¾‹: {missing_keys[:5]}")
            if unexpected_keys:
                print(f"å¤šä½™é”®ç¤ºä¾‹: {unexpected_keys[:5]}")
                
        del state_dict # ç«‹å³æ¸…ç†å†…å­˜
        
        # ğŸ”§ ä¸­é—´æ¸…ç†
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # 2. åˆå§‹åŒ–Uni3Dæ¨¡å‹ - å¼ºåˆ¶æœ¬åœ°æƒé‡
        print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ– Uni3D æ¨¡å‹...")
        eva_weights_path = Path("pretrained_weights/eva_giant_patch14_560.pt")
        uni3d_weights_path = Path("pretrained_weights/uni3d-g.pt")

        if not eva_weights_path.exists():
            raise FileNotFoundError(
                f"ğŸ”¥ é”™è¯¯: EVAæƒé‡æ–‡ä»¶æœªæ‰¾åˆ°! è¯·ç¡®ä¿ '{eva_weights_path}' å­˜åœ¨ã€‚"
            )
        if not uni3d_weights_path.exists():
            raise FileNotFoundError(
                f"ğŸ”¥ é”™è¯¯: Uni3Dæƒé‡æ–‡ä»¶æœªæ‰¾åˆ°! è¯·ç¡®ä¿ '{uni3d_weights_path}' å­˜åœ¨ã€‚"
            )
        
        # åˆ›å»ºæ¨¡å‹é…ç½®å‚æ•°
        class Args:
            pc_model = "eva_giant_patch14_560"
            pretrained_pc = str(eva_weights_path) if eva_weights_path.exists() else None
            drop_path_rate = 0.0
            pc_feat_dim = 1408     # EVA Giant transformer ç»´åº¦
            embed_dim = 1024       # åŒ¹é… EVA02-E-14-plus
            group_size = 64        # æ¯ç»„ç‚¹æ•°
            num_group = 512        # ç»„æ•°
            pc_encoder_dim = 512   # ç¼–ç å™¨è¾“å‡ºç»´åº¦
            patch_dropout = 0.0    # patch dropout ç‡
        
        args = Args()
        print(f"ğŸ“ ä½¿ç”¨æœ¬åœ°EVA Giantæƒé‡: {eva_weights_path}")
        self.uni3d_model = create_uni3d(args)
        
        # åŠ è½½Uni3Dé¢„è®­ç»ƒæƒé‡
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½Uni3Dé¢„è®­ç»ƒæƒé‡: {uni3d_weights_path}")
        checkpoint = torch.load(uni3d_weights_path, map_location='cpu', weights_only=False)
        
        # æŒ‰ç…§å®˜æ–¹ä»£ç çš„æ–¹å¼å¤„ç†æƒé‡é”®å
        if 'module' in checkpoint:
            print("âœ… ä½¿ç”¨ 'module' é”®åŠ è½½æƒé‡ï¼ˆå®˜æ–¹æ–¹å¼ï¼‰")
            state_dict = checkpoint['module']
        elif 'model' in checkpoint:
            print("âœ… ä½¿ç”¨ 'model' é”®åŠ è½½æƒé‡")
            state_dict = checkpoint['model']
        elif 'state_dict' in checkpoint:
            print("âœ… ä½¿ç”¨ 'state_dict' é”®åŠ è½½æƒé‡")
            state_dict = checkpoint['state_dict']
        else:
            print("âœ… ç›´æ¥ä½¿ç”¨æ ¹çº§åˆ«æƒé‡")
            state_dict = checkpoint
            
        # ä¸¥æ ¼åŠ è½½æƒé‡ï¼Œä¸å…è®¸ä¸åŒ¹é…
        try:
            missing_keys, unexpected_keys = self.uni3d_model.load_state_dict(state_dict, strict=True)
            print("âœ… Uni3Dé¢„è®­ç»ƒæƒé‡ä¸¥æ ¼åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ä¸¥æ ¼åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•éä¸¥æ ¼åŠ è½½...")
            missing_keys, unexpected_keys = self.uni3d_model.load_state_dict(state_dict, strict=False)
            print(f"âš ï¸ ç¼ºå¤±çš„é”®: {len(missing_keys)} ä¸ª")
            print(f"âš ï¸ å¤šä½™çš„é”®: {len(unexpected_keys)} ä¸ª")
            if missing_keys:
                print(f"ç¼ºå¤±é”®ç¤ºä¾‹: {missing_keys[:5]}")
            if unexpected_keys:
                print(f"å¤šä½™é”®ç¤ºä¾‹: {unexpected_keys[:5]}")
                
        del checkpoint, state_dict # ç«‹å³æ¸…ç†å†…å­˜
        
        # 3. è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        self.clip_model.eval()
        self.uni3d_model.eval()
        
        # ğŸ”§ æœ€ç»ˆæ¸…ç†
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # 4. åˆå§‹è®¾å¤‡çŠ¶æ€
        if self.enable_dynamic_offload:
            # åˆå§‹åœ¨CPUä¸Š
            self.device = self.cpu_device
            self._models_on_gpu = False
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–åœ¨CPUä¸Šï¼Œenable_offload=True")
        else:
            # ç›´æ¥ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
            self.device = self.target_device
            self.clip_model = self.clip_model.to(self.target_device)
            self.uni3d_model = self.uni3d_model.to(self.target_device)
            self._models_on_gpu = True
            print(f"âœ… æ¨¡å‹ç›´æ¥åŠ è½½åˆ° {self.target_device}")
        
        elapsed = time.time() - start_time
        print(f"âœ… Uni3D æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
        self._models_initialized = True
    
    def _fast_load_to_gpu(self):
        """ğŸš€ è¶…å¿«é€ŸGPUåŠ è½½ - ä½¿ç”¨å¼‚æ­¥æµå’Œç¼“å­˜"""
        if not self.enable_dynamic_offload or self._models_on_gpu:
            return
            
        print("âš¡ å¿«é€ŸåŠ è½½æ¨¡å‹åˆ°GPU...")
        start_time = time.time()
        
        with torch.cuda.device(self.target_device):
            # ä½¿ç”¨å¼‚æ­¥ä¼ è¾“æµåŠ é€Ÿ
            if self.stream:
                with torch.cuda.stream(self.stream):
                    self.uni3d_model = self.uni3d_model.to(self.target_device, non_blocking=True)
                    self.clip_model = self.clip_model.to(self.target_device, non_blocking=True)
                torch.cuda.synchronize()  # ç¡®ä¿ä¼ è¾“å®Œæˆ
            else:
                self.uni3d_model = self.uni3d_model.to(self.target_device)
                self.clip_model = self.clip_model.to(self.target_device)
        
        self.device = self.target_device
        self._models_on_gpu = True
        self._last_gpu_time = time.time()
        
        elapsed = time.time() - start_time
        print(f"âš¡ GPUåŠ è½½å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    def _fast_offload_to_cpu(self):
        """ğŸš€ å¿«é€Ÿoffloadåˆ°CPU"""
        if not self.enable_dynamic_offload or not self._models_on_gpu:
            return
            
        print("âš¡ å¿«é€Ÿoffloadæ¨¡å‹åˆ°CPU...")
        start_time = time.time()
        
        # å¿«é€Ÿç§»åŠ¨åˆ°CPU
        self.uni3d_model = self.uni3d_model.to(self.cpu_device)
        self.clip_model = self.clip_model.to(self.cpu_device)
        self.device = self.cpu_device
        self._models_on_gpu = False
        
        # å¼ºåˆ¶æ¸…ç†GPUç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        elapsed = time.time() - start_time
        print(f"âš¡ CPU offloadå®Œæˆï¼ŒGPUå†…å­˜å·²é‡Šæ”¾ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    def _meshes_to_pointclouds_torch(self, meshes: List[Mesh], num_points: int = 10000) -> torch.Tensor:
        """
        ğŸ”¥ æ‰¹é‡å¹¶è¡Œåœ°å°†å¤šä¸ªMeshå¯¹è±¡é«˜æ•ˆè½¬æ¢ä¸ºä¸€ä¸ªç‚¹äº‘å¼ é‡ã€‚
        """
        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼å¹¶è¡Œå¤„ç†æ¯ä¸ªmesh
        pointclouds = [self._mesh_to_pointcloud_torch(mesh, num_points) for mesh in meshes]
        
        # å°†æ‰€æœ‰ç‚¹äº‘å¼ é‡å †å æˆä¸€ä¸ªæ‰¹æ¬¡
        return torch.stack(pointclouds)

    def _mesh_to_pointcloud_torch(self, mesh: Mesh, num_points: int = 10000) -> torch.Tensor:
        """
        âš¡ é«˜æ•ˆçš„torchç‰ˆæœ¬meshåˆ°ç‚¹äº‘è½¬æ¢ï¼Œä¸¥æ ¼éµå¾ªUni3Då®˜æ–¹è§„èŒƒ
        1. é¢ç§¯åŠ æƒè¿‡é‡‡æ · -> 2. æœ€è¿œç‚¹é‡‡æ · (FPS) -> 3. æ ‡å‡†åŒ–
        """
        # 1. ä¸¥æ ¼æ£€æŸ¥meshæ•°æ®
        if not (hasattr(mesh, 'v') and hasattr(mesh, 'f') and
                mesh.v is not None and mesh.f is not None and
                len(mesh.v) > 0 and len(mesh.f) > 0):
            raise ValueError(
                f"ğŸ”¥ é”™è¯¯: æ— æ•ˆçš„meshæ•°æ®! é¡¶ç‚¹æ•°: {len(mesh.v) if hasattr(mesh, 'v') and mesh.v is not None else 'N/A'}, "
                f"é¢æ•°: {len(mesh.f) if hasattr(mesh, 'f') and mesh.f is not None else 'N/A'}"
            )

        vertices = mesh.v if torch.is_tensor(mesh.v) else torch.from_numpy(mesh.v).float()
        faces = mesh.f if torch.is_tensor(mesh.f) else torch.from_numpy(mesh.f).long()
        
        # 2. å¤„ç†é¢œè‰²ä¿¡æ¯
        if hasattr(mesh, 'vc') and mesh.vc is not None:
            vertex_colors = mesh.vc if torch.is_tensor(mesh.vc) else torch.from_numpy(mesh.vc).float()
            # ç¡®ä¿é¢œè‰²å€¼åœ¨ [0, 1] èŒƒå›´å†…ï¼ˆå®˜æ–¹Uni3Dè§„èŒƒï¼‰
            if vertex_colors.max() > 1.0:
                vertex_colors = vertex_colors / 255.0
        else:
            # ä½¿ç”¨é»˜è®¤é¢œè‰² 0.4 (å®Œå…¨æŒ‰ç…§å®˜æ–¹Uni3Då®ç°)
            vertex_colors = torch.ones_like(vertices) * 0.4
        
        # 3. âš¡ é«˜æ•ˆçš„é¢ç§¯åŠ æƒé‡‡æ · (å…¨torchæ“ä½œ)
        face_vertices = vertices[faces]  # (F, 3, 3)
        v0, v1, v2 = face_vertices[:, 0], face_vertices[:, 1], face_vertices[:, 2]
        
        # è®¡ç®—é¢ç§¯
        cross_product = torch.cross(v1 - v0, v2 - v0, dim=1)
        face_areas = 0.5 * torch.norm(cross_product, dim=1)
        face_probs = face_areas / face_areas.sum()
        
        # é‡‡æ ·è¶³å¤Ÿå¤šçš„ç‚¹
        initial_num_points = max(num_points * 2, 4096)
        sampled_face_indices = torch.multinomial(face_probs, initial_num_points, replacement=True)
        
        # åœ¨é‡‡æ ·é¢ç‰‡ä¸Šé‡å¿ƒåæ ‡é‡‡æ ·
        sampled_faces = face_vertices[sampled_face_indices]  # (initial_num_points, 3, 3)
        
        # é‡å¿ƒåæ ‡é‡‡æ ·
        r1 = torch.rand(initial_num_points, 1)
        r2 = torch.rand(initial_num_points, 1)
        
        # ç¡®ä¿ r1 + r2 <= 1
        mask = (r1 + r2) > 1
        r1[mask] = 1 - r1[mask]  
        r2[mask] = 1 - r2[mask]
        r3 = 1 - r1 - r2
        
        # è®¡ç®—é‡‡æ ·ç‚¹
        sampled_points = (
            r1 * sampled_faces[:, 0] + 
            r2 * sampled_faces[:, 1] + 
            r3 * sampled_faces[:, 2]
        )  # (initial_num_points, 3)
        
        # ä¸ºé‡‡æ ·ç‚¹è®¡ç®—é¢œè‰²ï¼ˆé‡å¿ƒåæ ‡æ’å€¼ï¼‰
        sampled_face_colors = vertex_colors[faces[sampled_face_indices]]  # (initial_num_points, 3, 3)
        sampled_colors = (
            r1 * sampled_face_colors[:, 0] + 
            r2 * sampled_face_colors[:, 1] + 
            r3 * sampled_face_colors[:, 2]
        )  # (initial_num_points, 3)
        
        # åˆå¹¶åæ ‡å’Œé¢œè‰²
        initial_pointcloud = torch.cat([sampled_points, sampled_colors], dim=1)  # (initial_num_points, 6)
        
        # 4. ğŸ”¥ å…³é”®ä¿®æ­£: ä½¿ç”¨æœ€è¿œç‚¹é‡‡æ · (FPS) æ›¿ä»£éšæœºé‡‡æ ·
        if initial_pointcloud.shape[0] > num_points:
            # FPSéœ€è¦ [B, N, 3] æ ¼å¼çš„è¾“å…¥
            xyz_for_fps = initial_pointcloud[:, :3].unsqueeze(0)  # å¢åŠ batchç»´åº¦
            fps_indices = _fps_pytorch(xyz_for_fps, num_points) # [1, npoint]
            
            # ä½¿ç”¨gatheræ“ä½œæ ¹æ®ç´¢å¼•é€‰æ‹©ç‚¹
            pointcloud = _gather_pytorch(initial_pointcloud.unsqueeze(0), fps_indices)[0] # ç§»é™¤batchç»´åº¦
        else:
            # å¦‚æœç‚¹æ•°ä¸è¶³ï¼Œç›´æ¥ä½¿ç”¨ (è¿™ç§æƒ…å†µå¾ˆå°‘è§)
            pointcloud = initial_pointcloud
        
        # 5. ğŸ”§ å…³é”®ï¼šä½¿ç”¨å®˜æ–¹pc_normalizeæ ‡å‡†åŒ–
        xyz = pointcloud[:, :3]  # (num_points, 3)
        colors = pointcloud[:, 3:]  # (num_points, 3)
        
        # å®˜æ–¹pc_normalizeå®ç° (torchç‰ˆæœ¬)
        centroid = torch.mean(xyz, dim=0)
        xyz = xyz - centroid
        m = torch.max(torch.sqrt(torch.sum(xyz**2, dim=1)))
        xyz = xyz / m
        
        # é‡æ–°ç»„åˆæ ‡å‡†åŒ–åçš„æ•°æ®
        normalized_pointcloud = torch.cat([xyz, colors], dim=1)  # (num_points, 6)
        
        return normalized_pointcloud

    def _check_auto_offload(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨offloadï¼ˆé•¿æ—¶é—´æœªä½¿ç”¨ï¼‰"""
        if (self.enable_dynamic_offload and self._models_on_gpu and 
            time.time() - self._last_gpu_time > self._gpu_timeout):
            print(f"â° {self._gpu_timeout}ç§’æœªä½¿ç”¨ï¼Œè‡ªåŠ¨offloadåˆ°CPU")
            self._fast_offload_to_cpu()
    
    @torch.no_grad()
    def __call__(self, 
                 meshes: Union[Mesh, List[Mesh]], 
                 images: Union[str, List[str]],
                 metadata: dict = None,
                 openshape_setting: bool = False) -> Tuple[List[float], dict]:
        """ğŸš€ ä½¿ç”¨å®˜æ–¹Uni3Dæµç¨‹çš„å›¾åƒ-3Dè¯„åˆ†å™¨"""
        
        # æ£€æŸ¥è‡ªåŠ¨offloadå’Œåˆå§‹åŒ–
        self._check_auto_offload()
        self._init_models()
        self._fast_load_to_gpu()
        
        start_time = time.time()
        
        # ç»Ÿä¸€è¾“å…¥æ ¼å¼
        if isinstance(meshes, Mesh):
            meshes = [meshes]
        if isinstance(images, str):
            images = [images]
            
        # ç¡®ä¿æ•°é‡åŒ¹é…
        if len(meshes) != len(images):
            if len(images) == 1:
                images = images * len(meshes)
            else:
                raise ValueError(f"Mesh æ•°é‡ ({len(meshes)}) ä¸ image æ•°é‡ ({len(images)}) ä¸åŒ¹é…")
        
        # ä½¿ç”¨å®˜æ–¹æµç¨‹å¤„ç†ç‚¹äº‘
        pc_tensor = prepare_pointcloud_batch(meshes, num_points=10000, 
                                           openshape_setting=openshape_setting)
        pc_tensor = pc_tensor.to(self.device)
 
        # æ‰¹é‡å¤„ç†å›¾åƒ
        from PIL import Image
        image_tensors = torch.stack(
            [self.clip_preprocess(Image.open(p).convert('RGB')) for p in images]
        ).to(self.device)
 
        # æ‰¹é‡æ¨ç†
        with torch.no_grad():
            # æå–ç‰¹å¾
            image_features = self.clip_model.encode_image(image_tensors)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            
            pc_features = self.uni3d_model.encode_pc(pc_tensor)
            pc_features = pc_features / pc_features.norm(dim=-1, keepdim=True)
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
            print(f"   image_features.shape: {image_features.shape}")
            print(f"   pc_features.shape: {pc_features.shape}")
            print(f"   image_features èŒƒå›´: [{image_features.min():.6f}, {image_features.max():.6f}]")
            print(f"   pc_features èŒƒå›´: [{pc_features.min():.6f}, {pc_features.max():.6f}]")
            print(f"   image_features å‡å€¼: {image_features.mean():.6f}")
            print(f"   pc_features å‡å€¼: {pc_features.mean():.6f}")
            print(f"   image_features L2èŒƒæ•°: {image_features.norm(dim=-1).mean():.6f}")
            print(f"   pc_features L2èŒƒæ•°: {pc_features.norm(dim=-1).mean():.6f}")
            
            # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆæ¨¡æ‹Ÿå®˜æ–¹main.py:556çš„ç›´æ¥çŸ©é˜µä¹˜æ³•ï¼‰
            dot_product = (image_features * pc_features).sum(dim=-1)
            print(f"   ç‚¹ç§¯ç»“æœ: {dot_product.cpu().tolist()}")
            
            similarity = torch.cosine_similarity(image_features, pc_features, dim=-1)
            print(f"   ä½™å¼¦ç›¸ä¼¼åº¦: {similarity.cpu().tolist()}")
            scores = similarity.cpu().tolist()
        
        # æ¸…ç†
        self._fast_offload_to_cpu()
        
        elapsed = time.time() - start_time
        avg_score = sum(scores) / len(scores) if scores else 0.0
        for i, score in enumerate(scores):
            print(f"âš¡ æ ·æœ¬ {i+1} åˆ†æ•°: {score:.4f}")
        print(f"â±ï¸ è¯„åˆ†è€—æ—¶: {elapsed:.2f}ç§’")
        
        return scores, {
            "num_meshes": len(meshes), 
            "avg_score": avg_score,
            "eval_time": elapsed
        }

def prepare_pointcloud_batch(meshes: List[Mesh], num_points: int = 10000, 
                          openshape_setting: bool = False) -> torch.Tensor:
    """
    å°†å¤šä¸ª mesh è½¬æ¢ä¸ºæ‰¹é‡ç‚¹äº‘æ•°æ®ï¼Œå®Œå…¨æŒ‰ç…§å®˜æ–¹ Uni3D æµç¨‹
    
    Args:
        meshes: kiui mesh å¯¹è±¡åˆ—è¡¨
        num_points: æ¯ä¸ªç‚¹äº‘çš„é‡‡æ ·ç‚¹æ•°ï¼ˆå®˜æ–¹é»˜è®¤ 10000ï¼‰
        openshape_setting: æ˜¯å¦ä½¿ç”¨OpenShapeè®¾ç½®ï¼ˆY-Zè½´ç¿»è½¬ï¼‰
        
    Returns:
        torch.Tensor: æ‰¹é‡ç‚¹äº‘æ•°æ®ï¼Œå½¢çŠ¶ (batch_size, num_points, 6)
    """
    pointclouds = []
    
    for mesh in meshes:
        # æŒ‰ç…§å®˜æ–¹æµç¨‹å¤„ç†æ¯ä¸ªmesh
        pointcloud = _sample_points_from_mesh_official(mesh, num_points, openshape_setting)
        pointclouds.append(pointcloud)
    
    return torch.stack(pointclouds, dim=0)

def _sample_points_from_mesh_official(mesh: Mesh, num_points: int = 10000, 
                                   openshape_setting: bool = False) -> torch.Tensor:
    """
    ä»å•ä¸ªmeshé‡‡æ ·ç‚¹äº‘ï¼Œå®Œå…¨æŒ‰ç…§å®˜æ–¹Uni3Dæµç¨‹
    """
    vertices = mesh.v if torch.is_tensor(mesh.v) else torch.from_numpy(mesh.v).float()
    faces = mesh.f if torch.is_tensor(mesh.f) else torch.from_numpy(mesh.f).long()
    
    initial_num_points = max(num_points * 3, 30000)
    
    # å¤„ç†é¢œè‰²ä¿¡æ¯ï¼ˆå®˜æ–¹æ–¹å¼ï¼‰
    if hasattr(mesh, 'vc') and mesh.vc is not None:
        vertex_colors = mesh.vc if torch.is_tensor(mesh.vc) else torch.from_numpy(mesh.vc).float()
        if vertex_colors.max() > 1.0:
            vertex_colors = vertex_colors / 255.0
    else:
        vertex_colors = torch.ones_like(vertices) * 0.4
    
    # é¢ç§¯åŠ æƒé‡‡æ ·
    face_vertices = vertices[faces]
    v0, v1, v2 = face_vertices[:, 0], face_vertices[:, 1], face_vertices[:, 2]
    
    cross_product = torch.cross(v1 - v0, v2 - v0, dim=1)
    face_areas = 0.5 * torch.norm(cross_product, dim=1)
    face_probs = face_areas / face_areas.sum()
    
    selected_faces = torch.multinomial(face_probs, initial_num_points, replacement=True)
    selected_face_vertices = face_vertices[selected_faces]
    
    # é‡å¿ƒåæ ‡é‡‡æ ·
    u = torch.rand(initial_num_points, device=vertices.device)
    v = torch.rand(initial_num_points, device=vertices.device)
    mask = u + v > 1.0
    u[mask] = 1.0 - u[mask]
    v[mask] = 1.0 - v[mask]
    w = 1.0 - u - v
    
    sampled_points = (
        w.unsqueeze(-1) * selected_face_vertices[:, 0] +
        u.unsqueeze(-1) * selected_face_vertices[:, 1] +
        v.unsqueeze(-1) * selected_face_vertices[:, 2]
    )
    
    selected_face_colors = vertex_colors[faces[selected_faces]]
    sampled_colors = (
        w.unsqueeze(-1) * selected_face_colors[:, 0] +
        u.unsqueeze(-1) * selected_face_colors[:, 1] +
        v.unsqueeze(-1) * selected_face_colors[:, 2]
    )
    
    # FPSä¸‹é‡‡æ ·
    if sampled_points.shape[0] > num_points:
        xyz_for_fps = sampled_points.unsqueeze(0)
        fps_indices = _fps_pytorch(xyz_for_fps, num_points)
        sampled_points = _gather_pytorch(sampled_points.unsqueeze(0), fps_indices)[0]
        sampled_colors = _gather_pytorch(sampled_colors.unsqueeze(0), fps_indices)[0]
    
    # å®˜æ–¹åæ ‡å¤„ç†æµç¨‹
    xyz = sampled_points
    rgb = sampled_colors
    
    if openshape_setting:
        xyz[:, [1, 2]] = xyz[:, [2, 1]]  # Y-Zè½´äº¤æ¢
        # normalize_pc
        centroid = torch.mean(xyz, dim=0)
        xyz = xyz - centroid
        m = torch.max(torch.sqrt(torch.sum(xyz**2, dim=1)))
        xyz = xyz / m
    else:
        # pc_normalize  
        centroid = torch.mean(xyz, dim=0)
        xyz = xyz - centroid
        m = torch.max(torch.sqrt(torch.sum(xyz**2, dim=1)))
        xyz = xyz / m
    
    # æœ€ç»ˆæ‹¼æ¥
    pointcloud = torch.cat([xyz, rgb], dim=1)
    return pointcloud

def main():
    """æµ‹è¯• Uni3D è¯„åˆ†å™¨"""
    scorer = Uni3DScorer(enable_dynamic_offload=True)
    print("âœ… Uni3Dè¯„åˆ†å™¨åˆå§‹åŒ–æˆåŠŸ")

if __name__ == "__main__":
    main() 