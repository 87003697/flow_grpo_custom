"""
Uni3D Scorer - ğŸš€ è¶…é«˜æ•ˆçš„3D meshè¯­ä¹‰è´¨é‡è¯„åˆ†å™¨ï¼Œä¼˜åŒ–CPU/GPU offload
"""
import torch
import torch.nn as nn
import numpy as np
import time
from typing import List, Union, Tuple
from pathlib import Path

# å¯¼å…¥æ­£ç¡®çš„æ¨¡å‹
import open_clip
from .models.uni3d import create_uni3d, Uni3D
from .models.mesh_utils import sample_points_from_mesh, Mesh

class Uni3DScorer:
    """ğŸš€ è¶…é«˜æ•ˆçš„Uni3Dè¯„åˆ†å™¨ï¼Œä¼˜åŒ–CPU/GPU offloadæ€§èƒ½"""
    
    def __init__(self, device="cuda", enable_dynamic_offload=True, target_device="cuda"):
        # ğŸ”§ è®¾å¤‡é…ç½®
        self.enable_dynamic_offload = enable_dynamic_offload
        self.target_device = torch.device(target_device if torch.cuda.is_available() else "cpu")
        self.cpu_device = torch.device("cpu")
        
        # ğŸ”§ æ¨¡å‹ç¼“å­˜çŠ¶æ€
        self._models_initialized = False
        self._models_on_gpu = False
        self._last_gpu_time = 0
        self._gpu_timeout = 30  # 30ç§’åè‡ªåŠ¨offload
        
        print(f"ğŸš€ FastUni3Dåˆå§‹åŒ–ï¼šenable_offload={enable_dynamic_offload}, target={target_device}")
        
        # ğŸ”§ åˆå§‹åŒ–æ¨¡å‹ï¼ˆå§‹ç»ˆåœ¨CPUä¸Šï¼ŒæŒ‰éœ€ç§»åŠ¨åˆ°GPUï¼‰
        self._init_models()
        
        # ğŸ”§ é¢„çƒ­GPU streamsä»¥åŠ é€Ÿä¼ è¾“
        if torch.cuda.is_available():
            self.stream = torch.cuda.Stream()
        else:
            self.stream = None
    
    def _init_models(self):
        """ä¸€æ¬¡æ€§åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½"""
        if self._models_initialized:
            return
            
        print("ğŸ”„ ä¸€æ¬¡æ€§åˆå§‹åŒ–Uni3Dæ¨¡å‹...")
        start_time = time.time()
        
        # ğŸ”§ å…ˆæ¸…ç†GPUç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # 1. åˆå§‹åŒ–CLIPæ¨¡å‹ - ä½¿ç”¨æ­£ç¡®çš„open_clipæ¥å£
        print("ğŸ”„ æ­£åœ¨åŠ è½½ CLIP æ¨¡å‹: EVA02-E-14-plus")
        clip_weights_path = Path("pretrained_weights/eva02_e_14_plus_laion2b_s9b_b144k.pt")
        print(f"ğŸ“ ä»æœ¬åœ°åŠ è½½ CLIP æƒé‡: {clip_weights_path}")
        
        if clip_weights_path.exists():
            # å…ˆåˆ›å»ºæ¨¡å‹æ¶æ„
            self.clip_model, _, self.clip_preprocess = open_clip.create_model_and_transforms(
                'EVA02-E-14-plus', 
                pretrained=None  # ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
            )
            # åŠ è½½æœ¬åœ°æƒé‡
            state_dict = torch.load(clip_weights_path, map_location='cpu', weights_only=False)
            self.clip_model.load_state_dict(state_dict, strict=False)
            # ğŸ”§ ç«‹å³æ¸…ç†state_dictå ç”¨çš„å†…å­˜
            del state_dict
        else:
            print("âš ï¸ æœ¬åœ°CLIPæƒé‡ä¸å­˜åœ¨ï¼Œä½¿ç”¨åœ¨çº¿ä¸‹è½½")
            self.clip_model, _, self.clip_preprocess = open_clip.create_model_and_transforms(
                'EVA02-E-14-plus', 
                pretrained='laion2b_s9b_b144k'
            )
        print("âœ… CLIP æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # ğŸ”§ ä¸­é—´æ¸…ç†
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # 2. åˆå§‹åŒ–Uni3Dæ¨¡å‹ - ä½¿ç”¨æ­£ç¡®çš„create_uni3dæ¥å£
        print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ– Uni3D æ¨¡å‹...")
        eva_weights_path = Path("pretrained_weights/eva_giant_patch14_560.pt")
        uni3d_weights_path = Path("pretrained_weights/uni3d-g.pt")
        
        # åˆ›å»ºæ¨¡å‹é…ç½®å‚æ•°
        class Args:
            pc_model = "eva_giant_patch14_560"
            pretrained_pc = str(eva_weights_path) if eva_weights_path.exists() else None
            drop_path_rate = 0.0
            pc_feat_dim = 1408     # EVA Giant transformer ç»´åº¦
            embed_dim = 1024       # åŒ¹é… EVA02-E-14-plus
            group_size = 64        # æ¯ç»„ç‚¹æ•°
            num_group = 512        # ç»„æ•°
            pc_encoder_dim = 512   # ç¼–ç å™¨è¾“å‡ºç»´åº¦
            patch_dropout = 0.0    # patch dropout ç‡
        
        args = Args()
        print(f"ğŸ“ ä½¿ç”¨æœ¬åœ°EVA Giantæƒé‡: {eva_weights_path}")
        self.uni3d_model = create_uni3d(args)
        
        # åŠ è½½Uni3Dé¢„è®­ç»ƒæƒé‡
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½Uni3Dé¢„è®­ç»ƒæƒé‡: {uni3d_weights_path}")
        if uni3d_weights_path.exists():
            checkpoint = torch.load(uni3d_weights_path, map_location='cpu', weights_only=False)
            # å¤„ç†æƒé‡é”®å
            if 'model' in checkpoint:
                state_dict = checkpoint['model']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            self.uni3d_model.load_state_dict(state_dict, strict=False)
            # ğŸ”§ ç«‹å³æ¸…ç†checkpointå ç”¨çš„å†…å­˜
            del checkpoint, state_dict
        print("âœ… Uni3Dé¢„è®­ç»ƒæƒé‡åŠ è½½æˆåŠŸ")
        
        # 3. è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        self.clip_model.eval()
        self.uni3d_model.eval()
        
        # ğŸ”§ æœ€ç»ˆæ¸…ç†
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # 4. åˆå§‹è®¾å¤‡çŠ¶æ€
        if self.enable_dynamic_offload:
            # åˆå§‹åœ¨CPUä¸Š
            self.device = self.cpu_device
            self._models_on_gpu = False
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–åœ¨CPUä¸Šï¼Œenable_offload=True")
        else:
            # ç›´æ¥ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
            self.device = self.target_device
            self.clip_model = self.clip_model.to(self.target_device)
            self.uni3d_model = self.uni3d_model.to(self.target_device)
            self._models_on_gpu = True
            print(f"âœ… æ¨¡å‹ç›´æ¥åŠ è½½åˆ° {self.target_device}")
        
        elapsed = time.time() - start_time
        print(f"âœ… Uni3D æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
        self._models_initialized = True
    
    def _fast_load_to_gpu(self):
        """ğŸš€ è¶…å¿«é€ŸGPUåŠ è½½ - ä½¿ç”¨å¼‚æ­¥æµå’Œç¼“å­˜"""
        if not self.enable_dynamic_offload or self._models_on_gpu:
            return
            
        print("âš¡ å¿«é€ŸåŠ è½½æ¨¡å‹åˆ°GPU...")
        start_time = time.time()
        
        with torch.cuda.device(self.target_device):
            # ä½¿ç”¨å¼‚æ­¥ä¼ è¾“æµåŠ é€Ÿ
            if self.stream:
                with torch.cuda.stream(self.stream):
                    self.uni3d_model = self.uni3d_model.to(self.target_device, non_blocking=True)
                    self.clip_model = self.clip_model.to(self.target_device, non_blocking=True)
                torch.cuda.synchronize()  # ç¡®ä¿ä¼ è¾“å®Œæˆ
            else:
                self.uni3d_model = self.uni3d_model.to(self.target_device)
                self.clip_model = self.clip_model.to(self.target_device)
        
        self.device = self.target_device
        self._models_on_gpu = True
        self._last_gpu_time = time.time()
        
        elapsed = time.time() - start_time
        print(f"âš¡ GPUåŠ è½½å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    def _fast_offload_to_cpu(self):
        """ğŸš€ å¿«é€Ÿoffloadåˆ°CPU"""
        if not self.enable_dynamic_offload or not self._models_on_gpu:
            return
            
        print("âš¡ å¿«é€Ÿoffloadæ¨¡å‹åˆ°CPU...")
        start_time = time.time()
        
        # å¿«é€Ÿç§»åŠ¨åˆ°CPU
        self.uni3d_model = self.uni3d_model.to(self.cpu_device)
        self.clip_model = self.clip_model.to(self.cpu_device)
        self.device = self.cpu_device
        self._models_on_gpu = False
        
        # å¼ºåˆ¶æ¸…ç†GPUç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        elapsed = time.time() - start_time
        print(f"âš¡ CPU offloadå®Œæˆï¼ŒGPUå†…å­˜å·²é‡Šæ”¾ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    def _check_auto_offload(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨offloadï¼ˆé•¿æ—¶é—´æœªä½¿ç”¨ï¼‰"""
        if (self.enable_dynamic_offload and self._models_on_gpu and 
            time.time() - self._last_gpu_time > self._gpu_timeout):
            print(f"â° {self._gpu_timeout}ç§’æœªä½¿ç”¨ï¼Œè‡ªåŠ¨offloadåˆ°CPU")
            self._fast_offload_to_cpu()
    
    def _compute_semantic_score(self, mesh: Mesh, image_path: str, num_points: int = 8000) -> float:
        """è®¡ç®—meshä¸å›¾åƒçš„è¯­ä¹‰ä¸€è‡´æ€§è¯„åˆ† - çœŸæ­£çš„å®ç°"""
        try:
            # 1. ä»meshé‡‡æ ·ç‚¹äº‘
            points, colors = sample_points_from_mesh(mesh, num_points)
            if points is None:
                print("âš ï¸ ç‚¹äº‘é‡‡æ ·å¤±è´¥")
                return 0.5
            
            # 2. å‡†å¤‡ç‚¹äº‘æ•°æ® (æ·»åŠ é¢œè‰²ç»´åº¦)
            if colors is None:
                # å¦‚æœæ²¡æœ‰é¢œè‰²ä¿¡æ¯ï¼Œè®¾ç½®ä¸ºç™½è‰²
                colors = np.ones_like(points)
            
            # ç»„åˆç‚¹äº‘å’Œé¢œè‰² [N, 6] = [x,y,z,r,g,b]
            pc_data = np.concatenate([points, colors], axis=1)
            pc_tensor = torch.from_numpy(pc_data).float().to(self.device)
            pc_tensor = pc_tensor.unsqueeze(0)  # [1, N, 6]
            
            # 3. åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
            from PIL import Image
            
            image = Image.open(image_path).convert('RGB')
            image_tensor = self.clip_preprocess(image).unsqueeze(0).to(self.device)
            
            # 4. æå–ç‰¹å¾å¹¶è®¡ç®—ç›¸ä¼¼åº¦
            with torch.no_grad():
                # æå–å›¾åƒç‰¹å¾
                image_features = self.clip_model.encode_image(image_tensor)
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)
                
                # æå–ç‚¹äº‘ç‰¹å¾ 
                pc_features = self.uni3d_model.encode_pc(pc_tensor)
                pc_features = pc_features / pc_features.norm(dim=-1, keepdim=True)
                
                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                similarity = torch.cosine_similarity(image_features, pc_features, dim=-1)
                score = float(similarity.cpu().item())
                
                # å°†ç›¸ä¼¼åº¦ä» [-1, 1] æ˜ å°„åˆ° [0, 1]
                normalized_score = (score + 1) / 2
                
                return normalized_score
                
        except Exception as e:
            print(f"âš ï¸ è¯­ä¹‰è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")
            return 0.5
    
    @torch.no_grad()
    def __call__(self, 
                 meshes: Union[Mesh, List[Mesh]], 
                 images: Union[str, List[str]],
                 metadata: dict = None) -> Tuple[List[float], dict]:
        """ğŸš€ è¶…é«˜æ•ˆå›¾åƒæ¨¡å¼è¯„åˆ† - çœŸæ­£çš„å®ç°"""
        

        
        # æ£€æŸ¥è‡ªåŠ¨offload
        self._check_auto_offload()
        
        # ç¡®ä¿æ¨¡å‹åˆå§‹åŒ–
        self._init_models()
        
        # å¿«é€ŸåŠ è½½åˆ°GPU
        self._fast_load_to_gpu()
        
        # ç»Ÿä¸€è¾“å…¥æ ¼å¼
        if isinstance(meshes, Mesh):
            meshes = [meshes]
        if isinstance(images, str):
            images = [images]
            
        # ç¡®ä¿ mesh å’Œ image æ•°é‡åŒ¹é…
        if len(meshes) != len(images):
            if len(images) == 1:
                images = images * len(meshes)
            else:
                raise ValueError(f"Mesh æ•°é‡ ({len(meshes)}) ä¸ image æ•°é‡ ({len(images)}) ä¸åŒ¹é…")
        
        # ğŸš€ çœŸæ­£çš„æ‰¹é‡è®¡ç®—è¯„åˆ†
        scores = []
        start_time = time.time()
        
        for i, (mesh, image_path) in enumerate(zip(meshes, images)):
            try:
                score = self._compute_semantic_score(mesh, image_path)
                scores.append(score)
                print(f"ğŸ¯ è¯„åˆ†æ ·æœ¬ {i+1}/{len(meshes)}: {score:.4f}")
            except Exception as e:
                print(f"âš ï¸ è¯„åˆ†æ ·æœ¬ {i+1} å¤±è´¥: {e}")
                scores.append(0.5)  # ä½¿ç”¨é»˜è®¤åˆ†æ•°
        
        # å¿«é€Ÿoffloadåˆ°CPU
        self._fast_offload_to_cpu()
        
        elapsed = time.time() - start_time
        avg_score = sum(scores) / len(scores) if scores else 0.0
        print(f"âš¡ è¯„åˆ†å®Œæˆï¼Œ{len(meshes)}ä¸ªæ ·æœ¬ï¼Œå¹³å‡åˆ†: {avg_score:.4f}ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
        
        # è¿”å›å…¼å®¹å¥–åŠ±ç³»ç»Ÿçš„æ ¼å¼
        return scores, {
            "num_meshes": len(meshes), 
            "avg_score": avg_score,
            "eval_time": elapsed
        }

def main():
    """æµ‹è¯• Uni3D è¯„åˆ†å™¨"""
    scorer = Uni3DScorer(enable_dynamic_offload=True)
    print("âœ… Uni3Dè¯„åˆ†å™¨åˆå§‹åŒ–æˆåŠŸ")

if __name__ == "__main__":
    main() 