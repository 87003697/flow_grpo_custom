import torch
import timm
import numpy as np
from torch import nn
from . import losses
from pathlib import Path

from .point_encoder import PointcloudEncoder

class Uni3D(nn.Module):
    def __init__(self, point_encoder):
        super().__init__()
        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))
        self.point_encoder = point_encoder

    def encode_pc(self, pc):
        xyz = pc[:,:,:3].contiguous()
        color = pc[:,:,3:].contiguous()
        pc_feat = self.point_encoder(xyz, color)
        return pc_feat

    def forward(self, pc, text, image):
        text_embed_all = text
        image_embed = image   
        pc_embed = self.encode_pc(pc)
        return {'text_embed': text_embed_all,
                'pc_embed': pc_embed,
                'image_embed': image_embed,
                'logit_scale': self.logit_scale.exp()}

def get_filter_loss(args):
    return losses.Uni3d_Text_Image_Loss()

def get_metric_names(model):
    return ['loss', 'uni3d_loss', 'pc_image_acc', 'pc_text_acc']

def create_uni3d(args):  
    # create transformer blocks for point cloud via timm
    if args.pretrained_pc and Path(args.pretrained_pc).exists():
        print(f"ğŸ“ ä»æœ¬åœ°åŠ è½½EVA Giantæƒé‡: {args.pretrained_pc}")
        # ğŸ”§ ä½¿ç”¨å®˜æ–¹æ–¹å¼ï¼šç›´æ¥é€šè¿‡checkpoint_pathå‚æ•°åŠ è½½
        try:
            point_transformer = timm.create_model(args.pc_model, 
                                                 checkpoint_path=args.pretrained_pc, 
                                                 drop_path_rate=args.drop_path_rate)
            print("âœ… EVA Giantæƒé‡é€šè¿‡checkpoint_pathåŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ checkpoint_pathæ–¹å¼å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°æ‰‹åŠ¨åŠ è½½æ¨¡å¼...")
            # å›é€€æ–¹æ¡ˆï¼šæ‰‹åŠ¨åŠ è½½
            point_transformer = timm.create_model(args.pc_model, pretrained=False, drop_path_rate=args.drop_path_rate)
            state_dict = torch.load(args.pretrained_pc, map_location='cpu')
            point_transformer.load_state_dict(state_dict, strict=False)
            print("âœ… EVA Giantæƒé‡æ‰‹åŠ¨åŠ è½½æˆåŠŸ")
    else:
        print(f"âš ï¸ EVA Giantæƒé‡ä¸å­˜åœ¨æˆ–æœªæŒ‡å®šæœ¬åœ°è·¯å¾„ï¼Œä½¿ç”¨åœ¨çº¿ä¸‹è½½")
        if args.pretrained_pc:
            print(f"   å°è¯•è·¯å¾„: {args.pretrained_pc}")
        print("ğŸ’¡ è¿è¡Œ python scripts/download_eva_weights.py æ¥ä¸‹è½½æƒé‡åˆ°æœ¬åœ°")
        # ä½¿ç”¨åœ¨çº¿æƒé‡
        point_transformer = timm.create_model(args.pc_model, pretrained=True, drop_path_rate=args.drop_path_rate)

    # create whole point cloud encoder
    point_encoder = PointcloudEncoder(point_transformer, args)

    # uni3d model
    model = Uni3D(point_encoder=point_encoder,)
    return model


